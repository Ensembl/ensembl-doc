\documentclass[a4paper,10pt]{article}
\usepackage{a4}
\usepackage{epsfig}
\parindent=0pt
\parskip=10pt
%\renewcommand{\baselinestretch}{2}

\title{Running the Ensembl Anopheles automatic annotation} 
\author{Emmanuel Mongin (mongin@ebi.ac.uk)}

\begin{document}

\maketitle


\bf{File last updated: E.Mongin Oct 2003; M.Hammond March 04}
The goal is to provide written help on how to run the the \textit{A. gambiae} automatic annotation. This should actually be usable for most of the 'virgin genomes'. This documentation for processes which are common with other genomes, references are given to files present in the ensembl CVS repository called ensembl-doc. These files should be updated as the processes and code change. All of this documentation is written for people working at EBI/Sanger. Please update this documentation if needed. In this file when a reference to release 3 is made (third anopheles annotation by Ensembl) this actually refer to the Ensembl release labeled 2a (still second assembly but third annotation). Removal of some proteins that probably represent bacterial contaminants from this set produced the annotation released as 2b.\\
\bf{Please update this file when it is needed.}

\section{Raw computes}
Running raw computes for \textit{A. gambiae} is pretty similar to other genomes -  only a few details change.
The document available is called using\_the\_ensembl\_pipeline. This is a pretty extensive and detailed document.

Here are the raw computes which have been run for the release 3:
\begin{itemize}
\item RepeatMask
\item TRF
\item tRNAscan
\item CPG island
\item DUST
\item Dros pep blastX hits
\item Swall blastX hits
\item Snap genes
\end{itemize}

\textbf{Particularities}\\
\textbf{RepeatMasker} is ran with a customed library (in the latest RepeatMastker directory there /usr/local/ensembl/lib/). The parameter used should be the following: \--lib anopheles.\\
\textbf{Genscan} has been tried with the arabidopsis matrix on Anopheles but gave pretty bad results. It is not worth rerunning again unless you an anopheles specific matrix has been created.
\textbf{Snap} (another \textit{ab initio} gene predictor) trained with anopheles specific ESTs (see section on how to train SNAP) gives much better result. In many regions it seems to get the right exon prediction, it does not tend to overpredict too much. However the transcript structure is not always right. Snap is used in the last part of the gene build and some SNAP genes (about 2000) will be elevated to the status of ***REMOVED*** gene (more details bellow on these genes).\\
\textbf{BlastX} is ran with two different datasets. The first one (and maybe the most important one) is the protein dataset containing all of the sequences from flybase. The second one is Swall.\\

NB: Make sure that the logic names in the analysis table. Please check with the web team.\\
The whole pipeline process (setting up the database and running it) should take about 3 days. On of the thing to do to get the analysis and rule tables right is to copy the ones from the previous release and have a critical look at them.

\section{Gene Build}
Gene build is perhaps the most tricky part of the process. Here are some of the reasons (I know they are obvious):
\begin{itemize}
\item No close annotated organism
\item Really few genes annotated (Immunity, odorant receptors, ...)
\item Few ESTs/cDNAs available (190 000 at 08/03)
\end{itemize}
One of the main change made to the process is to use much lower score blast hits. But this has many effects:

Here are the main issues, genebuilding on \textit{An. gambiae}:
\begin{itemize}
\item Extremely high number of potential parent proteins to be used fo the similarity process. This has for consequence an increase of the compute time and more noise brought to the exon structure
\item Genewise may built incomplete exons on low score blast hits. Transcritpts build with incomplete exons may not be merged with the correct exon structure and then produce wrong splice variants.
\item Problems in merging splice variant from a same gene. This is due to partial exon structure build through the similarity process (mainly due to the use of low score blast hits). As EST genes are being merged to the final gene build. These genes in some case are not merged properly with similarity genes
\item Incomplete Repeat dataset
\item False negative. Still a certain number (about 10\% for the last release) may be missed
\end{itemize}

\subsection{Gene build by similarity}
The score of the blast hits used to build similarity gene is much lower than for other organisms. We used a score down to 125 (lower than that seems to only bring noise, higer should obviously reduce the noise but some edges exons may be missed).
\\
NB: In the Blast conf file, there is an option to filter the blast hits. This has to be turned or too many blast hits would be stored in the database.

\subsubsection{Targetted}
Targetted process is undertaken with 3 dataset:
\begin{enumerate}
\item \textit{An. gambiae} genes in Swiss-Prot and SPTrEMBL.
\item Submitted genes to the gene name submission database. (a script exists in the script section of the texttt{ensembl\-genename} cvs repository). use the script (/script in the ensembl-genename CVS repository) dump\_translation.pl to get protein sequence out of the genename submission database. Don't forget to use the latest version of the databae. Ask the web team.
%get the name of the script
\item Protein available for the latest \textit{D. melanogaster} genome. (usually dump them from the Ensembl version of Drosophila.) This will allow to predict the drosophila orthologs. This has not been done already but since Drosophila is used this may be worth trying with all dipteran genes available, but check it it does not creat to much noise.
\end{enumerate}

Here is an example of the conf file used for the last release (release 3).%add conf file here
\begin{verbatim}
  # minimum required coverage for multiexon predictions
  GB_TARGETTED_MULTI_EXON_COVERAGE      => '25',
  
  # minimum required coverage for single predictions
  GB_TARGETTED_SINGLE_EXON_COVERAGE     => '90',
  
  # maximum allowed size of intron in Targetted gene
  GB_TARGETTED_MAX_INTRON               => '50000',
  
  # minimum coverage required to prevent splitting 
  #on long introns - keep it high!
  GB_TARGETTED_MIN_SPLIT_COVERAGE       => '95',
  
  # genetype for Targetted_GeneWise
  GB_TARGETTED_GW_GENETYPE              => 'TGE_gw',       
  GB_TARGETTED_MASKING => ['RepeatMask', 'Dust'],
  # [] no features being masked out
  # [''] all repeats being used 
  #if only some of the sets of repeats wants 
  #to be masked out put logic names of the 
  #analyses in the array 
  #e.g ['RepeatMask', 'Dust']
  GB_TARGETTED_SOFTMASK => 0, 
  # set this to one if you want the repeats 
  #softmasked ie lower case rather 
  than uppercase N's
\end{verbatim}

\textbf{potential problems}:
\begin{itemize}
\item Check for XXXs in the protein sequence. If a sequence has too many XXXs, pmatch may never end. Generally check that pmatch properly finished, it would fail if there is bad characters. Some of the drosophila proteins definitely have to be deleted.
\item After running pmatch(see ensembl-doc documentation) check at this step if most of the proteins have been mapped to the genome. 
\end{itemize}

\subsubsection{Similarity}
The similarity process uses both blast hits from Swall and Drosophila blastX hits. With the blast filtering code on (see example of the conf file, texttt{GB\_SIMILARITY\_BLAST\_FILTER)} all of the jobs should be finished after 24h (on the farm if not too loaded). This Blast filtering code is different than the one used at the Blast step. This option with filter only useful blast hits before running genewise cutting down the processing time by 10 folds.
\\
Here si an example of hte configuration file used for the last anopheles release for the similarity process:

\begin{verbatim}

  GB_SIMILARITY_DATABASES => [
    {                             
      'type'       => 'Swall',
      'threshold'  => '125',
      'index'      => '/data/blastdb/Ensembl/swall_030604',
      'seqfetcher' => 'Bio::EnsEMBL::Pipeline::
       SeqFetcher::OBDAIndexSeqFetcher'
    },
    {
      'type' => 'drosphila-peptides',
      'threshold' => '125',
      'index'   => 'drosophila-release3-peptides-unique_index',
      'seqfetcher' => 'Bio::EnsEMBL::Pipeline::
       SeqFetcher::OBDAIndexSeqFetcher',
    }
  ],
  # minimum required parent protein coverage
  GB_SIMILARITY_COVERAGE           => 40,
  
  # maximum allowed size of intron 
  GB_SIMILARITY_MAX_INTRON         => 10000,
  
  # minimum coverage required to prevent splitting on long introns - 
  #keep it high!
  GB_SIMILARITY_MIN_SPLIT_COVERAGE => 90,
  
  #low complexity threshold - transcripts whose 
  #translations have low complexity
  GB_SIMILARITY_MAX_LOW_COMPLEXITY => 70,
  
  # gene type for FPC_BlastMiniGenewise
  
  GB_SIMILARITY_GENETYPE           => 'similarity_pruned1',
  
  GB_SIMILARITY_MASKING => ['RepeatMask','DUST'],
  
  #the above setting will lead to RepeatMasker features 
  #being masked out, if  used no masking will take place,
  #if [''] is used all repeats in the 
  #table will be masked out
  #if only some of the sets of repeats wants 
  #to be masked out put logic names 
  #of the analyses in the array e.g ['RepeatMask', 'Dust']
  GB_SIMILARITY_SOFTMASK => 0, 
  
  # set this to one if you want the repeats 
  softmasked ie lower case rather than uppercase N's
  #No similarity genes will be build overlapping the 
  #gene type put in this list. If nothing is put, 
  #the default will be to take 
  #Targetted genewise genes
  
  GB_SIMILARITY_GENETYPEMASKED => ['TGE_gw','genomewise_final'],
  
  GB_SIMILARITY_BLAST_FILTER => 1,
  
\end{verbatim}


\textbf{potential problems}: 
\begin{itemize}
\item The score used for this run are low (125 for the blast hits) in some locus many spliced variants (or what will become spliced variants) with incomplete exons. Some of the transcripts may also span on two transcripts locus.
\item In the last gene build there is few cases where genes should have been build with similarity and where nothing was build. I'll leave a list of location where genes have been missed.
\item As we use low score blast hits a lot of wrong spliced variants may be build in later stage. One of the trick I've been using (that's definitely not the solution but this help waiting to find a solution), is to run the gene build over the similarity genes and limit the number of transcripts allowed for one cluster to 3. In that case only the 3 best transcripts from a cluster will be use.

\end{itemize}

\subsubsection{Combine with cDNAs}
This process will combine the cDNAs to the similarity genes to add UTRs where possible. The process used here is the same than for human. The only difference is (see EST gene build section) that we don't do separate EST gene build and cDNA gene build, thus all of the data available (EST + cDNA mapped) are used for this step. These ESTs and cDNA are mapped at the first step of the EST Gene build (see bellow, Exonerate step)
NB: Both Similarity gene build and EST gene build can be ran at the same time. Only the last steps (Gene combiner and gene builder requires to have both builds and obviously this combine step to have ESTs/cDNA mapped).

\subsection{EST Gene build}
\subsubsection{Exonerate and the EST gene builder}
\paragraph{Exonerate}
The EST gene build is ran without much adaptation to the process (for more detaisl see the conf files). As the number of ESTs anopheles remains relatively low (less than 200 000) and that they are of pretty good quality, we treat these data as cDNAs. For the last release all of the \textit{An. gambiae} sequences labelled as RNA have been used for the gene build. 
To map the EST to the genome, only exonerate has been used.
For documentation on how to run this build read in ensemb-doc, cdna analysis.txt.
Here is the configuration file used to run the Exonerate step (mapping of the ESTs to the genome):

\begin{verbatim}
  EST_INPUTID_REGEX => '(\S+)\.(\d+)-(\d+)',
  EST_RUNNER        => 'pipeline-new/
                        scripts/EST/run_exonerate.pl',     
  # path to pipeline-new/scripts/EST
  EST_SCRIPTDIR     => 'pipeline-new/scripts/EST/',
              
  # where the result-directories are going to go        
  EST_TMPDIR        => 'est_build/',          
  # job-queue in the farm
  LSF_OPTIONS       => '-q acari -C0',
  
  # make_bsubs.pl options
  EST_EXONERATE_BSUBS   => 'ests/bsubs/exonerate.bsub',
  
  # path to file containing ALL ESTs/cDNAs
  EST_FILE                    => 'total_ests_plus_submitted.fa',
  
  # path to directory where EST chunks live
  EST_CHUNKDIR                => 'ests/est_chunks/',
  
  # how many chunks?
  # for NCBI_28 we have 3690891 ests, at approx. 
  #350 ests per chunk, we estimate
  EST_CHUNKNUMBER             => 550,    
              
  # full path fo the dir where we have 
  #the masked-dusted chromosomes
  EST_GENOMIC                 => 'mosquito/genome/',
  
  # path to file with repeatmasked dusted genomic sequences
  # NB this file is huge - distribute it across the farm or 
  # be prepared to face the wrath of systems when the network 
  # seizes up!
  
  EST_EXONERATE              => 'ensembl/bin/exonerate-0.6.7',
  
  # if set to true, this option rejects unspliced alignments 
  #for cdnas that have an spliced
  # alignment elsewhere in the genome
  REJECT_POTENTIAL_PROCESSED_PSEUDOS => 0,
  
  # if set to true, the only the best match 
  #in the genome is picked
  # if there are several matches with the same coverage
  # all of them are taken, except single-exon 
  # ones if REJECT_POTENTIAL_PROCESSED_PSEUDOS is switched on 
  BEST_IN_GENOME => 1,
  
  EST_MIN_COVERAGE            => 95,
  EST_MIN_PERCENT_ID          => 97,
  

  EST_USE_DENORM_GENES  => 0,
  
  ############################################################
  # each runnable has an analysis
  ############################################################
  
  EST_EXONERATE_RUNNABLE     => 'Bio::EnsEMBL::Pipeline::
   RunnableDB::ExonerateToGenes',      
  EST_EXONERATE_ANALYSIS     => 'RNA_BEST',
  
  EST_SOURCE                  => 'EMBL',      
  
\end{verbatim}

\paragraph{EST Gene builder}
The configuration file for the EST gene build is pretty complex. The best is to chat with eduardo (eae@sanger.ac.uk) because there is a lot of development being undertaken and the following conf file may be outdated in a month 

\begin{verbatim}
  ############################################################
  # EST_GeneBuilder
  ############################################################
  
  EST_GENEBUILDER_CHUNKSIZE        => 1000000,      
  #  we use 1000000 (ie 1MB) chunks
  
  EST_GENEBUILDER_INPUT_GENETYPE => 'RNA',
  EST_GENOMEWISE_GENETYPE        => 'genomewise_final',
  
  # if this is set to TRUE it will reject ests that do not
  # have all splice sites correct
  CHECK_SPLICE_SITES => 1,
  
  # if set to a number, it will reject single exon ests 
  #that are shorter that this
  FILTER_ON_SINGLETON_SIZE => 500,
  
  # if set to a number, it will reject single exon ests 
  #that have score smaller than this
  RAISE_SINGLETON_COVERAGE => 97,
  
  ## you must choose one type of merging for cdnas/ests: 
  #2 and 3 are the common ones
  EST_GENEBUILDER_COMPARISON_LEVEL => 2,
  
  # for details see documentation 
  # in Bio::EnsEMBL::Pipeline::GeneComparison::TranscriptComparator
  # 1 --> strict: exact exon matching (unrealistic). 
  # 2 --> allow edge exon mismatches
  # 3 --> allow internal mismatches
  # 4---> allow intron mismatches
  # 5---> loose mode - consecutive exon overlap - allows intron mismatches
  
  # you can alow a mismatch in the splice sites
  EST_GENEBUILDER_SPLICE_MISMATCH  => 40,
  
  # you can allow matches over small introns 
  EST_GENEBUILDER_INTRON_MISMATCH => 20,
  
  # you can bridge over small introns: 
  #we difuse the small intron into one exon
  # if set to false transcripts with small introns will be rejected
  BRIDGE_OVER_SMALL_INTRONS => 0,
  
  # the maximum size of introns to bridge over
  EST_MIN_INTRON_SIZE  => 20,
  
  
  # you can choose whether you only want tw ests/cdnas to merge if
  # they have the same number of exons
  EST_GENEBUILDER_EXON_MATCH     => 0,
  
  # how much discontinuity we allow in the supporting evidence
  # this might be correlated with the 2-to-1 merges, so we
  # usually put it =  EST_GENEBUILDER_INTRON_MISMATCH for ESTs
  EST_MAX_EVIDENCE_DISCONTINUITY  => 2,
  REJECT_SINGLE_EXON_TRANSCRIPTS  => 0,
  GENOMEWISE_SMELL                => 0,
  
  # exons smaller than this will not be include in the merging algorithm
  EST_MIN_EXON_SIZE               => 10,
  
  # ests with intron bigger than this will not be incuded either
  EST_MAX_INTRON_SIZE             => 50000,
  
  # this says to ClusterMerge what's the minimum
  # number of ESTs/cDNAs that must be 'included' into a
  # final transcript
  CLUSTERMERGE_MIN_EVIDENCE_NUMBER => 1,
  
  # maximum number of transcripts allowed to 
  # be in a gene. Even by tuning the other parameteres
  # to keep this low, there will be always 
  #cases with more 20 even 50 isoforms
  # which, unless what you're doing is really targetted
  # to a known case or with very good quality ests/cdnas, it
  # is not very reliable.
  MAX_TRANSCRIPTS_PER_GENE => 8,
  
  # If using denormalised gene table, set this option to 1.
  EST_USE_DENORM_GENES => 0,
            
\end{verbatim}

\bf{NB:} One of the most important option of the configuration is the genebuilder comparison level. For the Anopheles EST gene build release 3 we used level 2. See the configuration file above or even better Eduardo's Cluster Merge paper to get a better idea of the comparison levels.

\subsubsection{GeneCombiner (merging EST genes with the similarity build)}
The gene combiner will combine EST genes with similarity genes. This will add EST genes where no similarity genes have been predicted and add spliced variants to similarity genes.
This is still under heavy developpment by Eduardo. Talk to him next time this process is ran. Many think may have changed. Looking at the release 3 data, it seems that some of the EST genes have not been added to the final set where no other similarity genes have been predicted or not added to a gene structure, where we would expect them to add a new splice variant. This issues have been sent to Eduardo who is looking into it.

\section{Adding SNAP genes}
SNAP is an \textit{ab initio} gene predictor written by Ian Korf (ik1@sanger.ac.uk). This program is trained with a specific set of Anopheles EST genes (see bellow) by Ian. This is so far the best open source gene predictor we have tested for anopheles. Snap genes will be added where neither similarity nor EST genes have been predicted. To add these genes we use the GeneBuilder over the set of genes coming from the GeneCombiner with a specific set of options. 

%Describe the options here

\section{Post Compute}
\subsection{Gene build check}
Many checks should be undertaken on the data before deciding if a gene build is ready to be released or not. Few utility scripts are available here: \texttt{ensembl-pipeline/scripts/post\_GeneBuild/}. A set of SQL statements to checks the data are available here: \texttt{ensembl-doc/post\_genebuild\_checks.txt}.\\
It is also useful to look at the data using Apollo, this allow to see the different steps in the gene build (looking at the intermediary genes) and then to see how the final genes have been build. The genome is actually small enough to allow somebody to have a look at all of the chromosomes with Apollo.\\
Also check the number of submitted genes predicted. This is really important to get more than 95\% of them as these are the first genes that the users will look at. This would be pretty bad to release missing half of the TEP genes. I usually run a rough mapping using pmatch and try to spot what has been missed. For genes which have been missed, it is useful to retrieve the protein annotation from the previous release and see how important these genes are.

\subsection{Protein Annotation}
Protein annotation is similar to any other genome. \\Look in \texttt{ensembl-doc/running\_protein\_annotation.txt}. Don't forget to copy the interpro (in interpro) and the intepro description (in Xref).

\subsection{Known gene mapping}
Running the known gene mapping, don't forget to specify that you are running it for anopheles (organism option). For the known gene mapping, will be use: SPTR file for \textit{Anopheles gambiae} in fasta and Swiss-Prot format. A dump of the translations of the gene name submited sequences (you can find the script to dump these translations in \texttt{ensembl-genename/scripts/dump\_translation.pl}). NB: The mapping of the submitted genes is done at the transcript level, thus if a gene has been submitted with many spliced variants, we will map Ensembl genes to the sliced variants names (which is usually the gene name followed by incremental letters or numbers).
The celera accession numbers (the ones used in the science issue) are automatically mapped (see the mapping configuration file). 
NB: Genes submitted by Ensembl to Genbank end up in SPTREMBL, these are predictions. These genes are labelled in the mapping process as prediction\_SPTREMBL and are not considered as known genes.

\subsection{Bacterial contamination}
It seems that the assembly contains some contigs and scaffolds that derive from bacterial DNA in the original DNA preparation used to make libraries.  These may be chance bacterial occupants of the gut but could possibly include interesting symbionts. Ensembl transcript predictions may get built on such scaffolds (most likely via bacterial entries from SwissProt/SPTrEMBL and SNAP ab initio predictions). Several hendred possible bacterial contaminants were tagged as such in the initial annotation deposited in GenBank, but this step was misssed in the first Ensembl annotation.  The second Ensembl annotation (2a) also originally omitted this tagging.  A list of probable bacterial transcript predictions was supplied by Pier Bork.  346 proteins (343 genes) on scaffolds not mapped to a chromosome arm were removed from the protein set (but left as genes/transcripts tagged 'bacterial\_contaminant') to produce a revised 2b set. A script to carry out the removal (including consequent id mapping) is here:\\
 \texttt{ensembl/misc-scripts/anopheles\_scripts/remove\_proteins\_from\_db.pl}.

\subsection{Transcripts built on >1 scaffold}
Consider whether to delete transcripts that cross scaffold boundaries (I think this was done in build 2 but not in 2a).  Those on the 'UNKN chromosome' especially are not going to be real. However, these predictions could include parts of 'real' transcripts, which would be lost with simple removal.

\subsection{ID mapping}
ID mapping is usually run by Craig (craig@ebi.ac.uk). Give them the old database and the new one. Have a look at the results, they give a pretty good idea at the quality of the gene build.

\subsection{Moving data around}
Don't forget about the EST genes database. This is is useful from the user point of view. However we don't need a specific EST database, thus dna\_align\_features from the EST gene database should be copied to the core database (also don't forget to copy the protein\_align\_feature if needed). Finally make sure that the analysis table is fine and if you have new logic names, let the web team know.

\subsection{Database integrity checks}
Before the database is handed over to the web team, the java test suite should be ran on the database. This should spot obvious errors.

\section{misc}
\subsection{Produce a training dataset for SNAP}
A training dataset has already been created for SNAP using a set of genes only predicted with EST evidences and having start, stop codons as well as 5' and 3' UTRs and consensus spliced sites. If there is a need to create a new training set, have a look at this script:\\
 \texttt{ensembl/misc-scripts/anopheles\_scripts/produce\_snap\_training\_set.pl}. This script may have to be adapted depending the needs.
The main contact for this is Ian Korf. He will use this training set to create a new set of HMMs.

\subsection{Mapping BAC clones, Markers and Karyotype}
BAC Clones mapping is currently done by Frank Collins's team. They map the BAC clones to scaffold coordinates. There is a script to use these data and map back the scaffolds to chromosome coordinates. This mapping has to be updated every time there is a change in the assembly. The script is located here:\\
 \texttt{ensembl/misc-scripts/anopheles\_scripts/format\_bacs.pl}.\\
The markers also have to be mapped to chromosome coordinates. The 2 previous marker mapping has been done using Blat and post process using the following script: \\
\texttt{ensembl/misc-scripts/anopheles\_scripts/format\_blat.pl}. But try to find out at the time you rerun the mapping (at the occasion of an assembly update) if no other procedure in place.\\
Finally, up to now the karyotype table has been create by hand using BAC clone mapping data from Frank Collin's. This is kind of painfull and may take a whole afternoon...

\section{Submitting a new annotation to GenBank}
When the data are about to be released and are in their final state, it is time to submit them to GenBank.
\begin{itemize}
\item{First download the sequin software from ncbi:\\ 
\texttt{http://www.ncbi.nlm.nih.gov/Sequin/download.html}. The best is to install it on acari (alpha machines). Use sequin to create a new submission master file, save it. This file will be saved with the .sqn extension. You can find documentation on sequin here: \\
\texttt{http://www.ncbi.nlm.nih.gov/Sequin/sequin.hlp.html}}
\item{You currently need four files with various kinds of information already prepared.  An 'annotation' file has the old Celera names of the scaffolds so you can generate the official sequence identifier for each scaffold.  A protein_annotation file has protein identifiers from the previous dump (parsed using the protein_annotation_from_embl.pl script, then revised to remove any multiple usage of the same id). A kill list (made with a location_check_for_dump.pl script) prevents using protein ids if an ensembl stable id has been assigned to something in a diferent location. A gene_name file has official gene names and descriptions from the Anopheles gene name database, linked to the seq_ref's that are used as xrefs. Edit by hand to make all the descriptions appropriate.}
\item{Dump all of the data using\\ 
\texttt{ensembl/misc-scripts/anopheles\_scripts/dump\_genebank.pl} script. You need to give to the scripts the database to connect to, the output directory and some mapping files (currently hardcoded - see above). This file will dump a .fsa (fasta sequence of the scaffold) and a .tbl (annotation) for each scaffolds.}
\item{Then create an asn file for each scaffold using tbl2asn2 (you can find documentation there:\\ 
\texttt{http://www.ncbi.nlm.nih.gov/Sequin/tbl2asn2.html}. This script will read the master file, .fsa and .tbl file and create .sqn files (in asn format) in the same directory than where .fsa and .tbl files are located. Here is an example of command line: \texttt{/tbl2asn -t master.sqn -p output/}. The directory can then be tared and gziped to be sent to genbank (after data checks obviously)}
\item{Data checks. .snp file produced by tbl2asn2 can be red by sequin. Submission can then be visualized graphically or in various formats as Genbank, EMBL. Finally you also can use the program asn2gb to produce genbank or embl flat files and do checks these data with what is stored in the database over the whole genome.}
\item{Submit your data to NCBI. Contact email:\\ Karen Clark (kclark@ncbi.nlm.nih.gov)}
\end{itemize}

\section{Future developpements}
\subsection{Transposons}
Transposons are currently in developpment. Ensembl should be able to handle transposon submission and storage soon in a database similar to the gene name submission database.
But still few things need to be done:
\begin{itemize}
\item{Create a transposon database or table linked to Ensembl core}
\item{Create a mapping procedure of the transposons to the genome. Transposons should be mapped at 100\% identity}
\item{Create a Transposon specific web page}
\end{itemize}

\subsection{ESTs}
This is still in discussion


\end{document}

