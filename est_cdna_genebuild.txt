Running a cdna or est based genebuild using the ensembl pipeline
################################################################


This is a document about running an est or cdna based genebuild

(Contact: ensembl-dev@ebi.ac.uk)

1. What you will need
#####################

In order to run this process you will need the following things

the ensembl core api
the ensembl-pipeline api
bioperl (we are currently using Bioperl 0.72, it will probably work
         with newer versions but we haven't tried it)


these should all be availble on the web and from cvs

Access to at least one mysql instance

the exonerate binaries installed this can be found in the exonerate
cvs package on the sanger cvs respository

access to the translate program from the squid utilities of HMMer
from http://hmmer.wustl.edu/.

access to chr_subseq program from the ensembl-cutils cvs package

access to some batch submission system and an appropriate
Bio::EnsEMBL::Pipeline::BatchSubmission module written for it

2. Overview
###########

This is the process used to align dna sequences in the form of cdnas or ests
to the genome and then used the alignments to predict gene structures.

All the gene structures must have supporting evidence usually in the form
of est/cdna alignments.

This process has 2 steps and needs a set of ests or cdnas in order to be
run

The process has 2 main stages


A. Exonerate

Exonerate is a program written by guy slater which will align
ests or cdnas to genome sequences and predict splice structures. 
The RunnableDB used to do this is ExonerateToGenes.pm which first performs
individual exonerate runs with each chromosome (normally softmasked) 
subsequently then performs a best in genome analysis on all the hits found.
These splice structures though do not necessarily translate


B. Est_Genebuilder

This stage runs the EST_Genebuilder module which uses the Clustermerge
algorithm which collapses down the aligned ests into a non redundant set
of alternative transcripts. The module also ensures that each structure
translates.

3. General preparation
######################

Its a good idea to have directories where you can keep all the 
stdout/stderr from the jobs, and for the data for the jobs. 

Get checkouts of the three pieces of code you need, ensembl, 
ensembl-pipeline and bioperl and make sure they are in your PERL5LIB

make sure you have access to binaries for exonerate which is availible in
the ensembl cvs under the exonerate package

setup the databases

this is a diagram of all databases you require


 _________  
|         |   sequence
|EST_REFDB|   pipeline database tables 
|_________|  
      |     
      |
  exonerate     __________ 
      |        |          | 
      |------->|  EST_DB  |
      |        |__________|    
      |             | 
      |             |
      |        est_genebuilder    
      |             |
      |             |
      |             |
      |         ___________ 
      |        |           | 
      |------->|EST_GENE DB|
               |___________|  


they all need to contain the core schema and these tables need to be
filled in clone, contig, assembly, analysis, meta, chromosome

the meta table should contain an assembly.default entry


| meta_id | meta_key         | meta_value |
+---------+------------------+------------+
|       2 | assembly.default | RGSC3.1    |

the analysis table should be identical in all the databases even down
to the analysis_id as at present if this is not the case it breaks
the pipeline system

the reference database GB_DB should also contain the pipeline tables
which can be found in ensembl-pipeline/sql/table.sql and whose function
are describe in using_the_ensembl_pipeline.txt, and it should contatin 
the sequence


Config
------

Currently there are two config files which need filling out
Bio::EnsEMBL::Pipeline::Config::cDNAs_ESTs::Exonerate and
Bio::EnsEMBL::Pipeline::Config::cDNAs_ESTs::EST_GeneBuilder_Conf.

As per usual these files exist in the respository as .example files
and you need to fill your options in and rename them without the .example

Both files contain a lot of options which can be ignored when running the
analyses using the pipeline. They also contain some common options.

EST_INPUTID_REGEX, the regular expression to parse the format of your input
ids, we tend to use chr_name.start-end as out format
EST_GENOMIC, the directory where the dusted softmasked chromosome
sequences live, note it is a good idea that this file is pushed
across what ever compute resource you are using so the files aren't read
over nfs

Both files contain database options

EST_REFDB options should refer to the pipeline and sequence database.
EST_DB options should refer to the data where the exonerate results should 
be written 
EST_GENEDB options should refer to the database where the EST_Genebuilder 
genes should be written



Exonerate.pm


EST_CHUNKDIR, the directory in which the fasta files of the chunks of the
sequences live (explained later)
EST_EXONERATE, tha path to exonerate, we are currently using version
0.6.7
EST_EXONERATE_OPTIONS, the options used for exonerate
REJECT_POTENTIAL_PROCESSED_PSEUDOS, if set to one this cause the filtering
to reject unspliced alignments if the est/cdna is aligned spliced elsewhere
BEST_IN_GENOME, if true the best in genome filter is used and only aligments
with the best score are take

EST_MIN_COVERAGE, the minimum coverage a sequence need to be accepted, we 
generally use 90 in order we don't take in rubbish
EST_MIN_PERCENT_ID, the minimum percentage identity. We generally use 97

EST_USE_DENORM_GENES, if this is set to one the RunnableDB will expect
you to have the denormalised tables loaded. The sql file can be found here 
ensembl-pipeline/sql/denormalised_genes.sql. This tables are to remove the 
need to map the alignments from chromosomal coordinates to contig 
coordinates and back again. They should be used if you have a large number 
of ests and expect a large number of hits 100,000 or more.



EST_GeneBuilder_Conf.pm

ESTGENE_TYPE, the gene type of the align,ents produces in the previous stage
this should normally be the same as the logic_name of that analysis.
USE_GENOMEWISE, we used to use genomewise to find the orf of these 
alignments now we use a program called translate.
MAX_NUMBER_ESTS, if the slice chunk has over this number of ESTs a filter 
procedure fires off we generally have this set to 200
CHECK_SPLICE_SITES, if this is true any alignments with non canonical splice
sites will be rejected
FILTER_ON_SINGLETON_COVERAGE, this will reject single exon alignments 
shorter than this length.
EST_GENEBUILDER_COMPARISON_LEVEL. This describes the different levels
of stringency under which the cdnas/ests are merged

for details see documentation 
in Bio::EnsEMBL::Pipeline::GeneComparison::TranscriptComparator
1 --> strict: exact exon matching (unrealistic). 
2 --> allow edge exon mismatches
3 --> allow internal mismatches
4---> allow intron mismatches
5---> loose mode - consecutive exon overlap - allows intron mismatches

we generally use level 3

The variables at this point at to do with which genes to accept. The 
file documents them well and the examples in the file are what we generally
use. You shouldn't need here to use denormalised genes.


The cdna databases are also generally not used anymore


4. Fetching and preparing the data
##################################

These analyses require to sets of data. The first is the est or cdna 
sequences you wish to align. These can be fetched from a variety of sources.

For human  and mouse ests we go though dbEST pulling out all the appropriate
ests. There is a script to do this is enembl-pipeline/scripts/EST/ called 
get_human_ests.pl. This script could be amended to pull any species
out of appropriate dbest files. 

For fugu ests were fetched from here

http://fugu.hgmp.mrc.ac.uk/Download/


For human and mouse cdnas we go to refseq and embl_vertrna to pull
the appropriate sequences out. 

the refseqs can be found on the ftp site in species specific directories, 
this is where the human one is. You will want the .fna file

ftp://ftp.ncbi.nih.gov/refseq/H_sapiens/mRNA_Prot/

for the embl sequences we pull the sequences from the embl vertrna set
using a script based on the get_human_ests.pl script above. 

What ever species you are analysing there will probabably need to find your
most appropriate est/cdna source. Its good to check any species specific
databases you know about. You can also use refseq and embl. You may find
srs at the ebi a useful tool for this

Once you have got your cdnas/ests you need to chunk then up into a series
of files. We generaly have chunks of about 100 sequences for cdnas or 300
sequences for ests. The chunking can be done with a utility which comes
with exonerate called 

 fastasplit <fastapath> <outputdir> <chunknum>
 
 <fastapath> = the myltiple-entry fastA file with the ests
 <outputdir> = dir where we're going to put the chunks
 <chunknum>  = total number of chunks

or you can do something similar to the script which chunks up the proteome
fasta file for the protein_annotation

ensembl-pipeline/scripts/protein_pipeline/chunk_protein_file.pl

The chunked files should be in this directory

EST_CHUNKDIR 

and their file names should be what is used as the input_ids for the 
exonerate job.

You also need fasta files of  dusted softmasked chromosomes pushed out
in a directory across your compute farm. Provided you have run both
dust and RepeatMasker as part of your raw compute run (see 
running_the_raw_computes.txt) you can use this script to dump the individual
sequences. ensembl-pipeline/scripts/Sequence/get_sequence_for_chr.pl


5. Running the Analysis
#######################

==============
=A. Exonerate=
==============

This stage involves using exonerate to map the cdnas/ests to the genome.
This module expects filenames as input ids ( this can be achieved using
the make_input_ids script). This stage uses the PipelineExonerate runnabledb


Once you have the sequence files rules and input_ids setup you should test
your set up this can be done outside the pipeline using the script

ensembl-pipeline/scripts/test_RunnableDB

or inside the pipeline by using the -idlist_file option which ensures
the pipeline only runs on the set of IDs in a file in this format

input_id  input_id_type

Once this stage has run you will need to check the output for any errors
which haven't been court by the pipeline. Some errors don't kill the process
so can only be spotted after the fact

this command should work on most *INX systems for searching for phrases

find ./ -name "*.err" -exec grep -q EXCE {} \; -print


presence of EXC, this mean an exception has been thrown and further 
checking will be required 

exon lies on a gap (prediction across a gap in the assembly)

You will see this phrase if you hit out of memory errors
GLib-ERROR 

Abort Can't and Problem and memory are also good words to search for

grepping the out files for exit codes is also a good idea

exit code 130 -> job was bkilled
          139 -> weird memory error
          2   -> sequence fetching prob? can indicate a dodgy node
          1   -> out of memory 

if there is any exit code present it means the LSF job didn't finish
sucessfully so you will probably want to look to see if the job ran as 
thought ie there is output if expected, an entry has been written to the
input_id_analysis table, the job didn't use significant amounts of memory
etc


====================
=B. EST_GeneBuilder=
====================

This is the modules which uses the CluterMerge algorithm to collapse down
the est/cdna based alignments into a non redundant set of transcripts with
complete open reading frames. It uses the RunnableDB EST_GeneBuilder and
takes slice names as input_ids we generally use 1MB slices.

Again you need entries in the analysis table, rules and input ids before
this can start and once this is all set up is it a good idea to test the
system as described above.

Also it is a good idea to check the output files for errors. Again you will
want to look for similar problems as described above



Analysis,          RunnableDB,           input size,             section

Exonerate          PipelineExonerate     CHUNK_FILE              A
EST_GeneBuilder    EST_GeneBuilder       1MSLICE                 B


Here is a description of the dependancies you may should see in this system


         SubmitChunk          SubmitSlice
         CHUNK_FILE            1MSLICE
              |                    |
              |                    |
              |                    |
              |                    |
          Exonerate                |
         CHUNK_FILE                |
              |                    |
              |                    |
              |                    /
        Exonerate_Wait           /  
         ACCUMULATOR           /    
              |              /               
              |            /            
              |          /          
        EST_GeneBuilder/
           1MSLICE




Checklist
=========

When running the est/cdna genebuild it is worth checking these things out
before you hit go

1. Do you have all the executables, and data files for the
analysis you want to run? are they push out across you compute 
farm where appropriate

2. Have you filled out all the config files in 
Bio::EnsEMBL::Pipeline::Config::cDNA_ESTs

3. Does BatchQueue.pm contain entries for all the analyses you wish to run

4. Have you filled in the analysis table

5. Have you filled in the rule tables

6. Are the appropriate dummy entries in the input_id_analysis table

7. Have you tested jobs for your different analyses

If the answers to all these questions are yes you are probably read
to set the RuleManager going


Here is an example of the conf file you may need to setup the analysis for
the genebuild using the analysis_setup.pl script 
(see using_the_ensembl_pipeline.txt)


None of these settings are specific to the anaysis but are their for the 
pipeline functionailty or just descriptive purposes

[SubmitChunks]
module=PipelineExonerate
type=CDNACHUNK


[cdna_exonerate]
db=rat_cdnas
db_file=rat_cdnas
module=PipelineExonerate
type=CDNACHUNK


[exonerate_wait]
module=Accumulator
type=ACCUMULATOR


[Submit1MSlice]
type=1MSLICE

[cdna_genebuilder]
module=EST_GeneBuilder
type=1MSLICE



[cdna_wait]
module=Accumulator
type=ACCUMULATOR


====================
=B. EST release    =
====================

1. Add fake stable IDs for genes, exons, transcripts, translations

eg

insert into gene_stable_id select gene_id, concat( 'ENSDARESTG',
lpad(gene_id,11,'0')), 0, now(),now() from gene;

insert into transcript_stable_id select transcript_id, concat(
'ENSDARESTT', lpad(transcript_id,11,'0')), 0 from transcript;

insert into translation_stable_id select translation_id, concat(
'ENSDARESTP', lpad(translation_id,11,'0')), 0  from translation;

insert into exon_stable_id select exon_id, concat(
'ENSDARESTE', lpad(exon_id,11,'0')), 0 from exon;

2. Run healthchecks (NB these may take a long time with such a large number of genes).
