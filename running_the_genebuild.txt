Running an assembly based genebuild using the ensembl pipeline
##############################################################

This is a document about how to run the genebuild.

(Contact: ensembl-dev@ebi.ac.uk)

1. What you will need
#####################

In order to run this process you will need the following things

the ensembl core api
the ensembl-pipeline api
bioperl (we are currently using Bioperl 0.72, it will probably work
         with newer versions but we haven't tried it)


these should all be availble on the web and from cvs

Access to at least one mysql instance

the genewise and rd-utils binaries installed
these can be found in the Wise2 and rd-utils cvs packages on the 
sanger cvs respository

access to some batch submission system and an appropriate
Bio::EnsEMBL::Pipeline::BatchSubmission module written for it

2. Overview
###########

The genebuild is the process by which protein and cdnas which have been
aligned to the genome are used to predict gene structures. The
structures are then collapsed down into a non redundant set of genes
with alternative transcripts.

All genes have supporting evidence in the form of the protein/cdna 
alignments which were used to build them


The genebuild process has several steps and needs several data sources


The data sources needed are, a core ensembl database loaded with dna
(see loading_sequence_into_ensembl.txt) tables which are required to be 
filled are clone, contig, dna, assembly, chromosome and meta, a set of 
exact protein matches to the genome (running_pmatchs.txt), a set of 
blast hits which are generally produced by running the raw computes
(running_the_rawcomputes.txt) and optionally a set of ab initio gene
predictions which should also come from the raw computes


The main genebuild has 6 main stages

A. The Pmatch run

Pmatch is used to find exact matchs of species specific proteins to the 
genome then find the best in genome matches for each protein 

B. The Targetted Build. 

This is where the alignments generated by using pmatch are used to seed
genewise alignments. The base RunnableDB used is FPC_Targetted_GeneWise.
During the process the pmatch features are fetched. The protein
sequences of the pmatch features is fetched and then those are reblasted
against the genome. The results from the reblast are used to seed 
genewise alignments which in turn produces gene structures


C. The Similarity Build

This is where the alignments from the blast to various protein sets
produced in the raw computes are used to seed genewise alignments.
The runnabledb used is FPC_BlastMiniGenewise and the procedure is basically
the same as for the targetted build but those regions which contain
genes which are predicted in the targetted stage are filtered out
as it is generally assumed that the targetted genes from exon matches to
proteins will be better than any genes build on the basis of similarity.


D. Adding UTRS

The cDNA based predictions (described in est_cdna_genebuild.txt) and the 
protein based predictions are combined using the runnabledb 
Combine_Genewises_and_E2G. Here if the cdna based predictions overlap 
with the protein based predictions the algorithym decides whether extra 
information can be added to the protein based preidction

E. GeneBuilder

here all the predictions mare are collapsed down into a not redundant 
set of transcripts. Ab initio predictions which are well supported by
blast results can also be added into the prediction set, all this
is done from the RunnableDB Gene_Builder

F. GeneCombiner

Here the cdna predictions are used to add either new predictions where 
they don't overlap with protein based predictions or they can also add
new alternative transcripts to existing genes.


The size of the pieces of chromosomes you should run these various analyses
on does some what depend on your genome, how much information you already
have about your genome and how much memory you compute systems have 
availible. It is best to run them on as large as pieces as possible that 
will run in a reasonable time (generally less than 24 hrs) and a reasonable
amount of memory

Stage A the pmatches are run on whole chromosomes, then the complete
results set . The subsequent stages B, C and D are generally run intiailly
on either 5MB or 1MB pieces or the largest size which can be managed if 
your scaffolds are smaller than that. These are the processes which are
particular time and memory intensive. The similarity stage is generally 
the worse and methods to deal with that are discussed later on. Stages
E and F are good to run on whole chromosomes if possible. E, the 
genebuilder stage may need to be run on smaller pieces if you are including
ab intio transcripts in thoses which can be added to the final gene set
as including those can significanly increase the runtime of the
genebuilder stage.



3. General preparation
######################

Its a good idea to have directories where you can keep all the 
stdout/stderr from the jobs, and for the data for the jobs. 

Get checkouts of the three pieces of code you need, ensembl, 
ensembl-pipeline and bioperl and make sure they are in your PERL5LIB

make sure you have access to binaries for genewise which is availble 
from the ensembl cvs under rd-utils and wise2 packages respectively

setup the databases

this is a diagram of all databases you require


This are the names found in 
Bio::EnsEMBL::Pipeline::Config::GeneBuild::Databases
 _______  
|       |   pmatches
| GB_DB |   features 
|_______|
      |
      |
targetted genewise
      |
      |
similarity genewise
      |	   
      |              __________	
      |             |          | 
      |------------>| GB_GW_DB |
      |             |__________|         ____________
      |                  |              |            |
      |-----------------\|/-------------| GB_cDNA_DB |
      |     combine genewises and cdnas |____________|
      |                  |
      |             _____|______	
      |            |            | 
      |            | GB_COMB_DB |
      |            |____________| 
      |                  |
       -----------------\|  
	            genebuilder
	                  _____|______	
                   |            | 
                   | GB_FINALDB |
                   |____________| 
                         |         
                         |
                    _____________
                   |             |
                   | FINAL_DB    |
                   |_____________|        
                    
FINAL_DB is currently defined in 
Bio::EnsEMBL::Pipeline::Config::GeneBuild::GeneCombiner

they all need to contain the core schema and these tables need to be
filled in clone, contig, assembly, analysis, meta, chromosome

the meta table should contain an assembly.default entry


| meta_id | meta_key         | meta_value |
+---------+------------------+------------+
|       2 | assembly.default | RGSC3.1    |

the analysis table should be identical in all the databases even down
to the analysis_id as at present if this is not the case it breaks
the pipeline system

the reference database GB_DB should also contain the pipeline tables
which can be found in ensembl-pipeline/sql/table.sql and whose function
are describe in using_the_ensembl_pipeline.txt


More info about the various databases:
--------------------------------------

Here we descibe the various databases and the configuration options 
relevant to each. These configuration options can be found in 
Bio::EnsEMBL::Pipeline::Config::Database

all these databases should contain contig, clone, dna, chromosome, 
assembly, meta and analysis tables filled in

* reference db ( or sometimes called dna db )
Contain the dna, the features from the pre-compute pipeline and the 
pmatch_features (included in the extra tables pmatch_feature and 
protein). All the other databases will use it as dna_db to get 
sequence when necessary. This database should also contain the pipeline
tables and be the database you point the RuleManager script at (see
using_the_ensembl_pipeline.txt)
Databases::GB_DBHOST
Databases::GB_DBNAME
Databases::GB_DBUSER
Databases::GB_DBPASS

* genewise db
In this database we will store the genes/transcripts/exon/translation/
supporting_evidence from the runs of similarity_genewise 
(FPC_BlastMiniGenewise) and targetted_genewise (FPC_TargettedGeneWise)
Databases::GB_GW_DBHOST
Databases::GB_GW_DBNAME
Databases::GB_GW_DBUSER
Databases::GB_GW_DBPASS   

* cdna db
this database contains the genes/transcripts/... from the analysis of 
cdnas with exonerate, This will be the equvalient database to  EST_DBNAME
from 
Databases::GB_cDNA_DBHOST
Databases::GB_cDNA_DBNAME
Databases::GB_cDNA_DBUSER
Databases::GB_cDNA_DBPASS

* combined genes db
This db will have the genes/... built by combining the cdnas from
GB_cDNA with the genewise genes.  Before running the combining code
(Combine_Genewises_and_E2Gs), you should copy all genewise genes (plus
translations,etc...)  into this database from GB_GW_DB. In this way we
assure that combined_genes will get different internal ids, which will
be less confusing during the GeneBuilder analysis.
Databases::GB_COMB_DBHOST             
Databases::GB_COMB_DBNAME
Databases::GB_COMB_DBUSER
Databases::GB_COMB_DBPASS

* final genes db
This database will have the genes built by GeneBuilder from the 
genewise and combined genes in GB_COMB_DB and the genescan prediction 
in GB_DB. 
Databases::GB_FINALDBHOST
Databases::GB_FINALDBNAME
Databases::GB_FINALDBUSER
Databases::GB_FINALDBPASS



Other Config
------------

The Genebuild also requires several other pieces of config filled out.
Some of these are required for the pipeline to run and this are located
in Bio::EnsEMBL::Pipeline::Config,

These files are General, BatchQueue and Blast and the entries are
descibed in using_the_ensembl_pipeline.txt. One thing to note
is you generally want to keep the output from your genebuild jobs so
you need the entries for these analysis in BatchQueue.pm to have
cleanup set to no rather than yes

The genebuild has several general config files two. These are found in
Bio::EnsEMBL::Pipeline::Config::GeneBuild

General.pm, this contains general options which are used by many of
the RunnableDBs

GB_INPUTID_REGEX, the regular expression which should be used to 
		  parse the input ids which should be in the format
		  chr_name.start-end, e.g our normal input ids look
		  like this 1.1-100000 and the regular expression
		  (^\S+)\.(\d+)-(\d+) will produce the three
		  separate values of 1, 1 and 100000 for the chromosome
		  name, start and end

GB_BMG_FILTER, whether to filter the hits from the reblast carried out
	       in BlastMiniGenewise based on score, we generally don't 
	       do this
GB_BMG_SCORE_CUTOFF, the score to use if filtering 


The other options are very rarely used by control how the blast hits
from the reblast stage in the BlastMiniGenewise runnable are dealt with

Scripts.pm, this contains settings mainlyused by scripts run before or
	    during the genebuild

GB_KILL_LIST, this is the path to a file which cotains a list of 
	      protein ids which shouldn't be used when building genes.
	      This tends to be because the protein is based on a repeat
	      retrovirus or is just labelled a hypothetical protein
	      The file we use can be located here 
	      ensembl-pipeline/scripts/GeneBuild/kill_list.txt


GB_PROTEOME_FILES, this is used in the new_prepare_proteome.pl script
		   

There are more options in this file but they are involved with the 
old way of running the genebuild and shouldn't be needed

Genewise.pm, these contains various setting used by the genewise 
	     program

GB_GENEWISE_EXE, the path to the genewise executable
GB_GENEWISE_MEMORY, the maximum amout of memory the genewise program
		    has avalible in its main calculation
GB_GENEWISE_GAP, the gap penalty
GB_GENEWISE_EXTENSION the gap extension penalty
GB_GENEWISE_SUBS the subsititution error rate
GB_GENEWISE_OPTIONS other genewise options

the defaults in the Genewise.pm.example file are the standard settings
we use for most builds. For the briggsae genebuild we increased the 
gap extension penalty as nematodes have significantly short introns
than humans

Now there are a series of specific config files for the various 
processes 

Pmatch.pm, this contains pmatch specific settings all of which need to
be set to somethings

GB_PFASTA this is the location of the complete proteome fasta file

GB_PMATCH this is the location of the pmatch binary

GB_PMATCH_MAX_INTRON this is a value used by the pmatch parsing code
when merging hits

GB_PMATCH_MASKING this is where you put the logic_names of any repeats
you want masked out in the genomic sequence
that will be passed to pmatch

GB_PMATCH_SOFTMASK if you want the repeats masked to be softmasked

GB_INITIAL_PMATCH_LOGICNAME this is the logicname of the first pmatch
analysis

GB_FINAL_PMATCH_LOGICNAME this is the logic name of the final analysis
which sorts out the best in genome hits from the pmatch results


Sequences.pm, this contains the location of sequence indexes

GB_PROTEIN_INDEX, this is the path to the directory/file used by 
		  the sequence index you are using. We generally use
		  ODBAIndexSeqFetcher

GB_PROTEIN_SEQFETCHER, this should be the perl path to the
		       seqfetcher you are using, all the Seqfetchers   
		       we have code for can be found in here
		       Bio::EnsEMBL::Pipeline::SeqFetcher
 

Targetted.pm, these are settings required for the Targetted stage
most of the variables should be fairly self explaintory, the .example
file should contain the settings we use as default for most of our builds

three variables to pay closer attention to are
GB_TARGETTED_GW_GENETYPE, this is the type which will be assigned to
each gene predicted during this process. We generally use the logic
name of the analysis object
GB_TARGETTED_MASKING, this is an array defines if repeatmasked seq is to
be fetched and what masking there should be if any. for the targetted 
jobs we generally use unmasked dna 
GB_TARGETTED_SOFTMASK, this flag would make any masking in lowercase
rather than Ns but as genewise currently doesn't recognise softmasking
it generally isn't used

Similarity.pm, these settings are required for the similarity stage
of the build

most of these settings like for Targetted are relatively self
explainatory and your should for the most part beable to use
the settings from the .example file

variables to note are

GB_SIMILARITY_DATABASES,
this is an array of hashes, each hash contains details
of once source of protein based blast hits, type should be the logic
name of the blast analysis, threshold is the score below which hits
aren't returned, index should be the path to the file/dir which contains
an index of the approriate protein sequences and seqfetcher should
be the perl path to the appropriate seqfetcher to get them out


GB_SIMILARITY_GENETYPEMASKED, this is a option you can use if you want
not run the similarity build over sequences which aren't the targetted
genes but something else like EST genes or cDNA genes, also if you 
put enmpty quotes in the array nothing will be masked. This was put in
for the anopheles ensembl build as the targetted genes for anopheles 
weren't very good

GB_SIMILARITY_BLAST_FILTER, this is an optional filter which
can be applied to blast results before the proteins are passed to 
BlastMiniGenewise


Combined.pm, this is used by stages which combine the cdna based 
predictions with the protein based predictions from genewise in
order to add UTRs to them

The important variables are

GB_COMBINED_GENETYPE, the genetype to assign to the new genes

GB_cDNA_GENETYPE, the gene type to fetch out of the cdna gene database


GeneBuilder.pm, this is used in the Genebuild stage

again most of this variables should be relatively self explainatory
but here a a few which are important

GB_USE_ABINITIO, this is a flag to switch on the use of ab initio 
predictions in the genebuild run. Ab initio predictions are generally only 
now used on genomes which have not much species specific data


GB_MIN_GENSCAN_EXONS the minimun number of exons a ab initio predictor has
to have before it can be used to build a prediction from

GB_GENSCAN_MAX_INTRON the maximun length of a ab initio predictions intron
if it is to be accepted as a real prediction     


GeneCombiner.pm this is used in the GeneCombiner stage

These variables should be relatively self explainitory 


Once all Configuration is filled in and the databases have been setup
you can start running the process. The system is run using a script
called RuleManager3.pl whose function is explained in the 
using_the_ensembl_pipeline.txt document. This script requires the 
presence of a set of pipeline tables which are also explained in this
document. Two of these tables describe the order in which different 
analyses should be run as part of the pipeline. The diagram found
in genebuild_control_flow.jpg should describe the standard
path which is take through the analyses


4. Running the Analyses
#######################

=====================
=A. The Pmatch Stage=
=====================

This stage involves usin pmatch a fast alignment program to find exact
matches between protein sequences and the genomic dna.

First you need to ensure you have pmatch installed. The you need to 
fetch the protein data which will be used. We generally use species 
specific proteins where they exist otherwise we use the closest existing 
set availible. For example for Human we use the human proteome, for
briggsae though we use wormpep the elegans proteome

The runnabledbs you should have in module column of your analysis table are
Pmatch.pm for the first step and BestPmatch.pm for the best in Genome 
filter

Data prep
---------

Many species proteome sets can be found at swissprot and refseq on these
two ftp sites

ftp://ftp.ncbi.nih.gov/refseq/

ftp://ftp.ebi.ac.uk/pub/databases/SPproteomes/
(note here the names of the files are the taxonomy ids 
which can be found in the ncbi taxonomy database)

at this point the genbank format or embl format files respectively are 
also collected as they are used later to add xrefs to the predicted
gene sequences and having out of sync files can cause problems

A complete proteome fasta file should be generated with the headers 
formatted so only the name you want to use for the protein is found
on the header line like this

>PROTEIN_ID
MSITHSBTREI

this complete proteome file can be produced using the new_prepare_proteome
script which can be found here

ensembl-pipeline/scripts/GeneBuild/new_prepare_proteome.pl

this should take all the files specified in GB_PROTEOME_FILES in
Scripts.pm and parse them to produce a fasta file
which will be written to GB_PFASTA as specified in Pmatch.pm

The complete proteome file should then be searched for proteins which 
contain long stretches of X's (ie more than 5) as these tend to make 
pmatch run out of memory as they can be matched to any sequence

Once you have your proteome file cleaned up it is a good idea to have it
pushed out to you compute farm as acessing it over the network will
tend to cause problems. It is also a good idea at this time index your
fasta file as the sequences will need to be fetched in later stages. 
Programs you can use to index the file include James Cuffs getseqs, Steve
Searles indicate or both blast types, NCBI and WU will allow indexing and
retrival of sequences from fasta files. This index should also be pushed
out across your compute farm.

Database setup
--------------

Aswell as having a core database with pipeline tables added and filled in
you will also need the pmatch tables. These can be found here:

ensembl-pipeline/sql/pmatch.sql

For an example of how the rules might run for the pmatches look at the
genebuild_control_flow.jpg. 


Running the Pmatches
--------------------

The pmatches are run with the RuleManager like all parts of the pipeline.
It is a good idea to test the system first by running a single job.
The easiet way to do this is to run the RuleManager with the -id_listfile
flag and pass in a file in the format input_id  input_id_type

The First pmatch stage is generally run on full chromosomes and the second
best in genome filter runs on the entire results set so its input id 
doesn't really matter but we generally set it to Genome

Once you test job has run sucessfully you should beable to start
the pipeline running.

Once all the pmatch and the best in genome pmatch job is finished before 
starting the next stage it is a good idea to look at the results and make
sure there aren't any proteins which have hit too the genome to many times
after the best in genome filter

This is a piece of sql which will help do that


SELECT protein.protein_id, count(pmatch_feature.feature_internal_id) 
       as count 
FROM protein, pmatch_feature, analysis 
WHERE protein.protein_internal_id = pmatch_feature.protein_internal_id 
AND pmatch_feature.analysis_id = analysis.analysis_id 
AND analysis.logic_name = 'BestPmatch' 
GROUP by protein.protein_internal_id ORDER by count having count >= 6;


Once you have a list of the ids which hit 6 or more times you need to 
check the annotations of those proteins to establish if they are rubish 
or not. Proteins labelled with names like histone or ubquitin need to be
kept as they are real highly repeated gene families but proteins whose
descriptions contain works like 'hypothetical', 'similar to' 'retroviral',
 'ORF', 'line repeat' or 'ENV should probably be deleted from the results 
set'. Any proteins which you delete from the results set should also have 
their ids added to the kill_list which can be found here

ensembl-pipeline/script/GeneBuild/kill_list.txt

adding the ids to the list means the proteins won't subsequently be used
in further stages of the genebuild 



========================
=B The Targetted Stage=
========================

This is where the best in genome exact mapping of proteins to the 
genome sequence produced in the pmatch stage are used to seed genewise
alignments to produce gene structures.


Before Starting
---------------

You need to ensure you have you genewise database setup including all 
the tables mentioned in the Database configuration section. You need
to make sure you have all the generic config filled out as well as the
Targgetted.pm file

You also need to make sure you can access an index file of the proteome
file which was used to run the pmatches as genewise requires the protein
sequences. This should of been both generated and pushed across the farm
already when preparing the data for the pmatches

The runnabledb which should be in the module column of your analysis table
for this is FPC_TargettedGenewise.pm

As a note it is a good idea to keep the output from these genebuild jobs
and this can be done by setting the cleanup option in the appropriate
BatchQueue hash to 'no' or at least ensuring it isn't yes

Running the Targetted Stage
---------------------------

Again it is a good idea to test one or a couple of jobs before setting
the pipeline off wholesale. This can be done as describe above or if you 
want to test outside of the batch submission system you can using this 
script:

ensembl-pipeline/scripts/test_RunnableDB

this takes the standard database arguments as well as a logic_name and an
input_id, This script as standard writes the results into the database and
an entry into the input_id_analysis table but both these behaviours can be
switched off


Error checking the Targetted Run
--------------------------------

It is sensible to go through the stderr and stdout file from the 
targetted run and check for errors as many processes inside this analyses
won't necessarily cause the job to be labelled as FAILED but will need 
checking to make sure things don't need rerunning or data doesn't need 
deleting

this command should work on most *INX systems 

find ./ -name "*.err" -exec grep -q EXCE {} \; -print

These are a set of standards errors it is good to keep an eye on

in the .err files

presence of EXC, this mean an exception has been thrown and further 
checking will be required 

exon lies on a gap (prediction across a gap in the assembly)
 
this happens if an exon lies across a gap in the assembly there is nothing
which can be done about it and it should just be left

Genewise run failed
this can happen for a few reasons, if you don't have enough memory 
genewise can fail. This will show an out of memory error. 

If the protein sequence looks too much like a dna sequence ie is mainly
ATGC genewise will produce this error

Warning Error
    Trying to make a protein sequence from a non protein base sequence
[P24856]. 


Errors which won't have an EXC

Invalid sequence for $id - skipping or Problems fetching sequence, this 
means for some reason the sequence wasn't retrived from the database. 
This probably means the fasta file the index is based on is out of sync 
with the protein set used to produce the seed alignments. If there are 
only a couple of these you can probably ignore them but if they are in 
significant  number you will need to resync the data and rerun the process

look for the words Problem or Can't as this generally means there has been
a uncaught perl error and the code is broken 


also look for Exit codes in the .out files

exit code 130 -> job was bkilled
          139 -> weird memory error
          2   -> sequence fetching prob? can indicate a dodgy node
          1   -> out of memory 

if there is any exit code present it means the LSF job didn't finish
sucessfully so you will probably want to look to see if the job ran as 
thought ie there is output if expected, an entry has been written to the
input_id_analysis table, the job didn't use significant amounts of memory
etc



========================
=C The Similarity Stage=
========================

This is where blast hits from the raw compute stage are used to seed 
genewise alignments to produce gene structures

The runnabledb you want in your analysis table for this analysis is
FPC_BlastMiniGenewise

Before Starting
---------------

You already have your genewise and reference databases setup from running
the pmatchs and the targetted stage. For the similarity stage you also 
access to the blastx results from the analyses run as part of you raw
computes. These should be in your reference database. You also need access
to indexes of the protein databases you blasted against as genewise 
requires the protein sequences. Again you need you configuration filled
out, appropriate entry put in the BatchQueue.pm file and the Similarity.pm
configuaration filled out.

Again keeping the output from these jobs is a good idea as they can
then be checked for errors one they have run

Running the Similarity Stage
----------------------------

Again it is a good idea to test one or two jobs before you start the 
wholescale run and both methods already mentioned can be used.

The similarity stage can the the slowest of the genebuild stages and jobs
can take up to 24hrs. The RuleManager will check how long jobs have been
running for (if the appropriate method is implemented in the 
batch submission module) and kill jobs which have been running longer than
the predefined time in the Config/General.pm config file by default this
is set to 24 hours.

We generally don't let jobs run for longer than 24hours as this is an 
inefficent way to use the compute resource. Jobs which do get killed 
generally get split into smaller pieces then rerun. For example if a
similarity job running on a 1MB piece runs for more than 24hrs we would
intially split that piece into 2 500KB chunks then rerun the analysis.
The smallest chunk you want to use somewhat depends on what genome you are
using but for human 200Kb is probably the smallest piece it is worthwhile 
running.


Error Checking
--------------

Again check though the files to make sure any small errors haven't occurred
too many times.



=================
=D. UTR Addition=
=================

The fourth analysis combines cdna alignments from exonerate with genes 
built from the protein based analyses to hopefully produce genes with 
UTR's. How the cdna genes are generated is explained in the document
est_cdna_genebuild.txt The runnabledb used to do this is 
Combined_gw_and_e2g.pm

Before Starting
---------------

As before you need the Reference database with pipeline tables and the 
genewise database. You also need the database where your cdna results have
been written and a database to write the results of this combination too.
As well as all the standard configuration you have already filled out you 
also need to add another entry to the BatchQueue.pm and fill out the 
Combined.pm file in the Genebuld config

Running the UTR Addition
------------------------

Like the previous analyses it is good to both test a couple of jobs first
and save the output so it can be checked for errors once the analysis is 
complete



================
=E. Genebuilder=
================

The fifth analysis runs an set of heuristics which collapses down all the
predicted transcripts into a non redundant set genes and transcripts

Before Starting
---------------

You need to make sure all your databases are set up, you will need another
where the final genes can be written, all your config has been filled out

We Generally run this stage on full chromosome so you may want an 
accumulator stage between the UTR addition and this one as the input id
type will be changing

Running the Genebuilder
-----------------------

Again test a couple of runs first before running everything and also 
remember to check the output for any strange errors



=================
=F. GeneCombiner=
=================


The sixth analysis is where the cdna genes built in the cdna analysis are
used to fill gaps in the protein based gene build and also potentially
add extra transcripts to already existing genes.

Here is it best to use same species cdnas are more distantly related cdnas
can results is very odd looking genes.


Before Starting
---------------

Again you need all you databases and config setup. Currently genecombiner
only uses the config found in 
Bio::EnsEMBL::Pipeline::Config::GeneBuild::GeneCombiner although there are
plans to considate its config into the rest of the structure

You also need to have a set of genes built from your cdna alignments.
How this is done is described in est_cdna_genebuild.txt. 

Running the Genecombiner
-----------------------

Again test a couple of runs first before running everything and also 
remember to check the output for any strange errors



Once you have completed all these steps you may want run the pseudogene
analysis which is described in Pseudogenes.txt


Here is a summary of the analysis you need to run along with the module
they use and the size piece we run on. There is also a checklist for
before and after the


Analysis,          RunnableDB,           input size,             section

Pmatch             Pmatch                slice, full chromosomes A
BestPmatch         BestPmatch            genome (all results)    A
TGE_gw             FPC_TargettedGenewise 5MBslice                B
similarity_genewise FPC_BlastMiniGenewise 5MBslice               C
UTR_Addition        Combined_gw_and_e2g   5MSlice                D
Genebuilder         Gene_Builder          Chromosome             E
GeneCombiner        GeneCombiner          5MSlice                F


Remember after each stage is run you need to check the output for any
strange errors (see end of section B for a description).




Checklist
=========

When running the raw computes it is worth checking these things out
before you hit go

1. Do you have all the executables, and data files for the
analysis you want to run? are they push out across you compute 
farm where appropriate

2. Have you filled out all the config files in 
Bio::EnsEMBL::Pipeline::Config::Genebuild

3. Does BatchQueue.pm contain entries for all the analyses you wish to run

4. Have you filled in the analysis table

5. Have you filled in the rule tables

6. Are the appropriate dummy entries in the input_id_analysis table

7. Have you tested jobs for your different analyses

If the answers to all these questions are yes you are probably read
to set the RuleManager going


Here is an example of the conf file you may need to setup the analysis for
the genebuild using the analysis_setup.pl script 
(see using_the_ensembl_pipeline.txt)

In these analysis objects there are no setting which are specific to the
data you are using. You should note that all this objects do need a 
input_id_type as specified by the type variable and if at anypoint the
type of a goal analysis isn't the same as the type of the conditional
analysis you need an accumulator between the two and another condition
of the same type to provide the appropriate input_ids 


[SubmitChr]
type=CHROMOSOME


[Pmatch]
db=rodent_proteins
module=Pmatch
type=CHROMOSOME

[Pmatch_Wait]
module=Accumulator
type=ACCUMULATOR

[SubmitGenome]
module=dummy
type=GENOME

[BestPmatch]
db=rodent_proteins
module=BestPmatch
type=GENOME

[Best_Wait]
module=Accumulator
type=ACCUMULATOR

[Submit5MSlice]
type=5MSLICE

[TGE_gw]
module=FPC_TargettedGeneWise
type=5MSLICE

[similarity_genewise]
module=FPC_BlastMiniGenewise
type=5MSLICE


[SubmitChunks]
module=PipelineExonerate
type=CDNACHUNK

[exonerate]
db=rat_est
program=exonerate
program_version=0.6.7
program_file=exonerate
module=ExonerateToGene
gff_source=exonerate
gff_feature=est
type=CDNACHUNK

[exonerate_wait]
module=Accumulator
type=ACCUMULATOR

[combined_gw_e2g]
module=Combine_Genewises_and_E2Gs
type=5MSLICE


[Comb_Wait]
module=Accumulator
type=ACCUMULATOR

[ensembl]
module=Gene_Builder
type=CHROMOSOME

[Final_Wait]
module=Accumulator
type=ACCUMULATOR

[cdna_genebuilder]
module=EST_GeneBuilder
type=5MSLICE

[cdna_wait]
module=Accumulator
type=ACCUMULATOR

[genecombiner]
module=GeneCombiner
type=5MSLICE












