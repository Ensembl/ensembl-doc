this document should describe what is needed in order to run pmatches
against your genome in a pipeline fashion so the
Targetted Genewises can be run

The pmatch analysis finds exact matches of proteins to the genome and 
then filter them to find the best in genome hits plus those hits whose
identity lie within 2% of the best in genome hit.

if you have any questions contact ensembl-dev@ebi.ac.uk

last update 01/08/03


What you need
+++++++++++++

In order to run this you need

Bioperl.0.72
core ensembl
ensembl-pipeline

You also need a core database which contains your genome
and also had pipeline tables added and loaded 
for what the pipeline tables are and how to load them see
using_the_ensembl_pipeline.txt


What to do
++++++++++

========
=Config=
========

first out the config

there are 6 Config files which need at least partially filling out 
before you can run the pmatchs

3 of the config files can be found in

ensembl-pipeline/modules/Bio/EnsEMBL/Pipeline/Config/GeneBuild/

Pmatch.pm, this contains pmatch specific settings all of which need to
be set to somethings

GB_PFASTA this is the location of the complete proteome fasta file

GB_PMATCH this is the location of the pmatch binary

GB_PMATCH_MAX_INTRON this is a value used by the pmatch parsing code
when merging hits

GB_PMATCH_MASKING this is where you put the logic_names of any repeats
you want masked out in the genomic sequence
that will be passed to pmatch

GB_INITIAL_PMATCH_LOGICNAME this is the logicname of the first pmatch
analysis

GB_FINAL_PMATCH_LOGICNAME this is the logic name of the final analysis
which sorts out the best in genome hits from the pmatch results

Scripts.pm this contains variables used by scripts as part of the
genebuild, it currently needs several other config files to exist to
compile (see use statements are top) but most of the variables don't 
need to be filled in

GB_KILL_LIST should be the path to a file called kill_list.txt located
in ensembl-pipeline/scripts/GeneBuild/ this file contains
the ids of proteins which are repeats or pseudo genes so either cause
erroneous predictions or cause problems with pmatch

GB_PROTEOME_FILE this is an array used by new_prepare_proteome.pl. it
contains an anonyomous hash which specifies fasta file
locations and a regex to parse the desired id out of the header


General.pm this contains general settings for the GeneBuild

GB_INPUTID_REGEX this is the regular expression which will parse chr name,
start and end out of your input_ids
e.g cb25.fpc4171.1-10000 would have a regex of (^\S+\.\S+)\.(\d+)-(\d+)
where as 1.1-10000 would have a regex of (\S+)\.(\d+)-(\d+)

There are also 3 config files in Bio/EnsEMBL/Pipeline/Config which
need filling out

General.pm, BatchQueue.pm and Blast.pm and what goes in them should
be described in using_the_ensembl_pipeline.txt


==================
=Data preperation=
==================

Once the config is filled out you need to produce a complete proteome 
file

this is done by taking fasta files of you prefered datasources and 
parsing them to produce a single file with headers in the format
understood by the Pmatch Runnable.

to do this use the script

ensembl-pipeline/scripts/GeneBuild/new_prepare_proteome.pl

this should take all the files specified in GB_PROTEOME_FILES in
Scripts.pm and parse them to produce a fasta file
which will be written to GB_PFASTA as specified in Pmatch.pm


the data sources generally used for the pmatch stage are specific
specific proteins or if there are none of those proteins from closely
related organisms

For human, mouse rat and zebrafish we use the refseq proteins
which can be found here

ftp://ftp.ncbi.nih.gov/refseq/

For human mouse and rat we also use the sptrembl proteomes we
can be found here

ftp://ftp.ebi.ac.uk/pub/databases/SPproteomes/

(note here the names of the files are the taxonomy ids 
which can be found in the ncbi taxonomy database)

at this point teh genbank format or embl format files respectively are 
also collected as they are used later to add xrefs to the predicted
gene sequences and having out of sync files can cause problems

for other species such are briggsae closely related proteins files
are used in this case wormpep

once you have the proteome file look for any proteins with long stretches
of X's and delete them as otherwise it will cause pmatch to below up in
memory as it matches X to any other amino acid

=========================
=Setting up the Database=
=========================

Once you have your proteome file you need to make sure you database
contains the tables in ensembl-pipeline/sql/pmatch.sql

you also must ensure the appropriate core and pipeline tables are
filled out

your database needs sequence (contig, clone, dna, chromosome, assembly
meta) it also needs analysis objects for all analyses required for the
pmatch pipeline to work (5 described later)

the rule tables, the input id analysis table and the input id type 
analysis table also need to be filled out 
(see using_the_ensembl_pipeline.txt)


the dependancies required for the pmatch pipeline to run are as such:

5 analysis objects are required, two to actually describe the analysis
being done and point to the RunnableDBs Pmatch and BestPmatch, 
These should have the logic names used in the Pmatch config file and
point at the Pmatch RunnableDB for the initial stage and the BestPmatch
 RunnableDB for the final stage. Two dummy analysis to point at entries
 in the input_id_analysis table are also required as is one ACCUMULATOR
 analysis to bridge the change in input id between Pmatch and 
BestPmatch and this needs to run the runnabledb Accumulator. 
All these analysis also need input_id_types. The Pmatch analysis is 
best run on whole chromosomes the best type to specify is CHROMOSOME 
and use the make_input_ids to make slice ids for your whole chromosomes
The BestPmatch analysis needs to be run on the whole genome so the best
input id type is GENOME. The make_input_ids script should also beable
to add a input_id to the input_id_analysis for this too.  Pmatches 
dummy analysis and BestPmatches dummy analysis obviously need the same
 type as Pmatch and BestPmatch and the accumulator analysis need the 
type ACCUMULATOR. All the analyses can be added using the add_analysis
 script described in using_the_ensembl_pipeline.txt

You also need three Rules in the rule tables

the first rules goal should be Pmatch and it should depend on the 
Pmatch dummy analysis. The second rule goal should the accumulator 
analysis and the third rule goal should be be BestPmatch and it
should depend on the BestPmatch dummy analysis and accumulator analysis
so the Pipeline is aware that it has to wait for all the pmatches to 
run before it can run the accumulator and hence the BestPmatch analysis

You also need to fill out the input_id_analysis table with input ids

Once you have filled out all the tables you need to run the RuleManger
script which again is described in the using_the_ensembl_pipeline.txt
document

as a warning these jobs can sometimes fail with no good reason just a 
hardware glitch or hiccup (we you can see by looking at the stdout and 
err files) but if you have the retries value in your BatchQueue.pm set 
to more than 1 these jobs will be retried and should  work. If they fail
 4 times running with a consitent error then there is probably a problem


