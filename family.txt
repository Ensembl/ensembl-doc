 -*- mode: text -*-;

(For maintainer description, see below)

User description (should this go elsewhere?):

  The family database is generated by running Enright and van Dongen's Tribe
  sequence clustering algorithm on a set of peptides consisting of the
  EnsEMBL predictions, together with all vertebrate sequences from SWISS-PROT
  and SPTREMBL. When the clusters have converged, a 'consensus description'
  for the clusters is automatically generated from the SWISS-PROT/SPTREMBL
  description lines of all the SWISS-PROT/SPTREMBL members of each
  cluster. The annotation score is the percentage of SWISS-PROT/SPTREMBL
  family members that have this annotation, or part of it, in
  SWISS-PROT/SPTREMBL. If the description covers less than 40% of the
  SWISS-PROT/SPTREMBL members, the family description is assigned 'UNKNOWN'.

  NOTE: the family identifiers, members and descriptions used in the
  current release (1.10) are different from those used in previous
  releases. They will be stable as of this release.


------------------------------------------------------------------------
####
# admin description:
####

# this describes the way to go from ensembl.pep to the family database.
# 
# Still incomplete; not yet tested myself, so possibly wrong/inaccurate in
# places.  The blasting/clustering code is not (yet?) part of EnsEMBL; it
# currently lives in Anton's acari home, ~ae1/{srs,bin,blast} etc.

# First thing to do is to get the code

    cd work  # or whereever you keep your working copies

    cvs -d somewhere checkout ensembl-external # or cvs update, of course

# set/adjust some environment variables (FAMPATH and PATH).
# Look at ensembl-external/family/setenv.{shl,csh}.example; copy it and change
# to needs, then source it

    source setenv.sh

# If you're doing the source inside ensembl-external/family, you won't need 
# any adjustment (because it uses the value of `pwd`). It might be better to
# hardcode this though (so you can source it from elsewhere).

# Next, compile things

    cd src

    make

# that should be it

# ------------------------------------------------------------------------

# Getting the data.
# get swiss-prot/sptrembl data from SRS:

    cd  srs

    fetch.pl swissprot sptrembl


# gets all vertebrate seqs into vertebrate.pep and seq_types (latter says
# wether a seq camefrom swissprot or trembl; needed later during annotation
# phase).

# ------------------------------------------------------------------------
# get the EnsEMBL data
#  simply get it from the ensembl-ftp server or so. You may in fact need to
#  get several ensembl sets, e.g. mouse + human. 

# ------------------------------------------------------------------------
# concatenate:

    thedate=`date`

    cat ensembl.pep vertebrate.pep > $thedate.pep

# or: cat ensembl.pep mouse.pep vertebrate.pep > $thedate.pep (etc.)

    rm ensembl.pep vertebrate.pep # to save space. But keep seq_types

# ------------------------------------------------------------------------
# set the location of a scratch area, and create a directory for it:
# (I'm using sh syntax; use  ``set foo = bar'' when using csh syntax):


    release=fam112  # or whatever

    work=/work1/$USER/$release # or whaterver

    mkdir $work

    cd $work

    mkdir $work/blast

    mkdir $work/blast/seq

    mkdir $work/blast/results

    cd $work/blast

    formatdb_2.0.11 -p T  -i $work/srs/$release.pep


# results in $work/srs/$release.{pep,phr,pin,pesq}: the blast db to be run
# against

# ------------------------------------------------------------------------
# distribute the databases to all the cluster nodes:

    cd /data/sync

    mkdir  $release

    cd $release

    cp $work/blast/$release.* ./

    sync-data

# this will copy everything locally to the farm machines; takes an hour
# or so. 

# ------------------------------------------------------------------------
# split the data to be blasted into chunks:

    cd $work/blast

chopper $work/srs/$release.pep -n 400  # see also -h
# splits data into $work/blast/seq/

# ------------------------------------------------------------------------
# submit to blast: 

    cd $work/blast

    run-blasts.pl  /data/sync/$release.pep  # see also -h !

# This will show what would be done, but not do it
# If all seems well, do:

    run-blasts.pl  -g /data/sync/$release.pep

# ------------------------------------------------------------------------
# when blast finished (10 hours or so)

# check results:

# you can already check results during the running:

    run-blasts.pl -C /data/sync/$release.pep

# and already re-submit the failed ones (still during running):

    run-blasts.pl -C -g  /data/sync/$release.pep

# If you're sure that missing results are not due to jobs that haven't
# completed (e.g., if no lsf jobs are outstanding), then resubmit all those
# whose counts don't add up:

    run-blasts.pl -C -f -g /data/sync/$release.pep

# For e.g. testing, you can restrict the jobs to be checked/submitted using
# the -n option

# ------------------------------------------------------------------------

# concatenate results and compress things

    concat-blasts.sh results/*.out.gz > $release.parsed

# this will tell you how many peptides it found (on stderr), and this should
# match the number of peptides in $release.pep

# ------------------------------------------------------------------------
# convert blast hits to a markov matrix:

    markov $release.parsed -ind $release.index -out $release.mci

# (you may need to play with the -chunk option; see markov -h)

# This may take 30-300 min, and 1.5 Gbyte of memory. 
# ------------------------------------------------------------------------
# run clustering algorithm on the matrix:

    mcl $release.mci -I 3.0 -progress 100

# takes 15 min or so. 

# -I is the inflation parameter: the higher, the more (and smaller) families
# will be.

# this produces  out.mcl; rename it to something more specific
  
  mv out.mcl $release.mcl  

# ------------------------------------------------------------------------
# put the numbers and strings back together again:

    parse_mcl.pl $release.mcl $release.index > $release.clusters

# This is a file of clusters-number, protein member (sorted by number of
# members, so the biggest clusters is at the end; first ~ third of the file is
# singletons)

# ------------------------------------------------------------------------

#  add the sp/trembl annotation lines (to each sp/trembl seq):

    add-annotations.pl $work/srs/$release.pep $work/srs/seq_types \
       $release.clusters > $release.annotated

# ------------------------------------------------------------------------

# run the 'consensifier', with swiss-prot as well as sptrembl annotation:

    anotater_sprot annotate.out > consensus.swissprot

    anotater_sptre annotate.out > consensus.sptrembl

# by now, there are many non-hits that have dropped out (sequences that
# did't even match themselves during the blast hits, due to low-complexity
# filtering. These are typically short repetive sequence). 

# ------------------------------------------------------------------------

# finally, put everything together using

    assembl2.pl annotate.out consensus.swissprot consensus.sptrembl >  final.families

# have a look at assembl2.pl; you can skip annotation words there (e.g., new
# id's of databases that are not particularly informative, like /RIK$/ or
# /image:/ 

# ------------------------------------------------------------------------
# now import stuff into an ensembl-family database:

# If the ENSP's are not yet final (e.g., if they look like COBP or PGBP or
# so), then remap the ID's, using

    pep-id-remap.pl mapping.dat  < final.family > families.out


# ------------------------------------------------------------------------

# load the families into the database:

    tablesql=$work/head/ensembl-external/sql/family.sql

    ensdb='database=homo_sapiens_core_110;host=ensrv3;user=ensro'

    famdb='database=family110;host=ensrv3;user=***REMOVED***'

    perl $scripts/family-input.pl -r 3 -C $tablesql \

    -E $ensdb -F $famdb final.families  > famload.out 2> famload.err

# this may fail if the database or tables already exist; if so, just leave
# out -C $tablesql (which creates the database and tables), and you should be
# fine.

# Very occasionally, you get one protein ending up in two families. This is
# rare, and harmless. If this happens, this is notified by family-input.pl,
# and the first one is taken, the rest ignored. 
# 
# The family-input.pl script tries to be careful with going from peptides
# (which the clusters contain) to genes (which are 'added' to the
# clusters). Occasionally, two peptides/transcripts from one gene end up in
# two different clusters. In that case, the family (and therefore
# description) having the best description is given  precedence. This is all
# written about to stderr, which is analyzed in the next step.
# 
# ------------------------------------------------------------------------

# Lastly, on the logfile from the loading (famload.err), run the statistics
# script:

     $scripts/fam-stats.sh ensrv3 family110 ***REMOVED*** famload.err  > stat.out 2> stat.err

# The output gives a rough summary of the way things have  been going (in
# particular, the gene->family assignents. They should be roughly equal
# numbers (although I have seen +- 50% ... not sure what to make of that, it
# looked OK).
# 
# If the gene-descriptions (see gene-descriptions.txt) have not been done
# yet, do them, then run the script 

    ensembl/scripts/desc-from-fam.sh coreDB -h host -u user famDB

# and replace the existing gene-description table with the new one (which is
# created in famDB.
