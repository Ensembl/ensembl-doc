 -*- mode: text -*-;

(For maintainer description, see below)

User description (should this go elsewhere?):

  The family database is generated by running Enright and van Dongen's Tribe
  sequence clustering algorithm on a set of peptides consisting of the
  EnsEMBL predictions, together with all vertebrate sequences from SWISS-PROT
  and SPTREMBL. When the clusters have converged, a 'consensus description'
  for the clusters is automatically generated from the SWISS-PROT/SPTREMBL
  description lines of all the SWISS-PROT/SPTREMBL members of each
  cluster. The annotation score is the percentage of SWISS-PROT/SPTREMBL
  family members that have this annotation, or part of it, in
  SWISS-PROT/SPTREMBL. If the description covers less than 40% of the
  SWISS-PROT/SPTREMBL members, the family description is assigned 'UNKNOWN'.

  NOTE: the family identifiers, members and descriptions used in the
  current release (1.10) are different from those used in previous
  releases. They will be stable as of this release.


------------------------------------------------------------------------
####
# admin description:
####

# this describes the way to go from ensembl.pep to the family database.
# 
# Still incomplete; not yet tested myself, so possibly wrong/inaccurate in
# places.  The blasting/clustering code is not (yet?) part of EnsEMBL; it
# currently lives in Anton's acari home, ~ae1/{srs,bin,blast} etc.

# ------------------------------------------------------------------------

# get swiss-prot/sptrembl data from SRS:
$ cd  srs
$  fetch.pl swissprot sptrembl

# gets all vertebrate seqs into vertebrate.pep and seq_types (latter says
# wether a seq camefrom swissprot or trembl; needed later during annotation
# phase).

# ------------------------------------------------------------------------
# get ensembl data
#  simply get it from the ensembl-ftp server or so.

# ------------------------------------------------------------------------
# concatenate:

thedate=`date`
$ cat ensembl.pep vertebrate.pep > $thedate.pep

$ rm ensembl.pep vertebrate.pep # keep seq_types

# ------------------------------------------------------------------------
# set the location of a scratch area, and create a directory for it:
release=fam112  #or whatever
work=/work1/$USER/$release # or whaterver
mkdir $work
cd $work
$ mkdir $work/blast
$ mkdir $work/blast/seq
$ mkdir $work/blast/results
$ cd $work/blast
$ formatdb_2.0.11 -p T  -i $work/srs/$thedate.pep

# results in $work/srs/$thedate.{pep,phr,pin,pesq}: the blast db to be run
# against

# ------------------------------------------------------------------------
# distribute the data:

$ cd /data/sync
$ mkdir  $release
$ cd $release
$ cp $work/blast/$thedat.* ./
$ sync-data

# this will copy everything locally to the farm machines; takes an hour
# or so. 

# ------------------------------------------------------------------------
# split data into chunks:

# when done:

$ cd $work/blast
chopper $work/srs/$thedate.pep -n 400  # see also -h
# splits data into $work/blast/seq/

# ------------------------------------------------------------------------
# submit to blast: 

$ cd $work/blast
$ run-blasts.pl  /data/sync/$thedate.pep  # see also -h !

# This will show what would be done, but not do it
# If all seems well, do:

$ run-blasts.pl  -g /data/sync/$thedate.pep


# ------------------------------------------------------------------------
# when blast finished (10 hours or so)

# check results:

# you can already check results during the running:

run-blasts.pl -C /data/sync/$thedate.pep

# and already re-submit the failed ones (still during running):

run-blasts.pl -C -g  /data/sync/$thedate.pep

# If you're sure that missing results are not due to jobs that haven't
# completed (e.g., if no lsf jobs are outstanding), then resubmit all those
# whose counts don't add up:

run-blasts.pl -C -f -g /data/sync/$thedate.pep

# For e.g. testing, you can restrict the jobs to be checked/submitted using
# the -n option

# ------------------------------------------------------------------------

# concatenate results and compress things
$ concat-blasts.sh results/*.out.gz > results.parsed
# this will tell you how many peptides it found (on stderr), and this should
# match the number of peptides in $thedate.pep

# ------------------------------------------------------------------------
# convert blast hits to a markov matrix:

$ markov results.parsed2 

# this will produce proteins.index proteins.mcl, matrix.mcl ???

# takes 30 min.  or so
# ------------------------------------------------------------------------
# run clustering algorithm on the matrix:
$ mcl mtarix.mcl -I 3.0 -progress 100

# takes 5 min or so. 
# -I is the inflation parameter: the higher, the more families and the
# smaller the families are. 

# this produces  out.mcl
# ------------------------------------------------------------------------
# put the numbers and strings back together again:

$ parse_mcl.pl out.mcl protein.index > ensembl.clusters

# ------------------------------------------------------------------------

#  add the sp/trembl annotation lines (to each sp/trembl seq):

$ annotate.pl $work/srs/$thedate.pep $work/srs/seq_types ensembl.clusters

# this produces annotate.out, which is the input for the consensus script

# ------------------------------------------------------------------------

# run the 'consifier', with swiss-prot as well as sptrembl annotation:

$ anotater_sprot annotate.out > consensus.swissprot
$ anotater_sptre annotate.out > consensus.sptrembl

# by now, there are many non-hits that have dropped out (sequences that
# did't even match themselves during the blast hits, due to low-complexity
# filtering. These are typically short repetive sequence). 

# ------------------------------------------------------------------------

# finally, put everything together using

$ assembl2.pl annotate.out consensus.swissprot consensus.sptrembl > \
   final.families

# have a look at assembl2.pl; you can skip annotation words there (e.g., new
# id's of databases that are not particularly informative, like /RIK$/ or
# /image:/ 

# ------------------------------------------------------------------------
# now import stuff into an ensembl-family database:

# If the ENSP's are not yet final (e.g., if they look like COBP or PGBP or
# so), then remap the ID's, using

scripts=$workingdir/ensembl-external/scripts
$ $scripts/pep-id-remap.pl mapping.dat  < final.family > families.out

# ------------------------------------------------------------------------

# load the families into the database:

$ tablesql=$work/head/ensembl-external/sql/family.sql
$ ensdb='database=homo_sapiens_core_110;host=ensrv3;user=ensro'
$ famdb='database=family110;host=ensrv3;user=***REMOVED***'
$ perl $scripts/family-input.pl -r 3 -C $tablesql \
    -E $ensdb -F $famdb final.families  > famload.out 2> famload.err

# this may fail if the database or tables already exist; if so, just leave
# out -C $tablesql (which creates the database and tables), and you should be
# fine.

# Very occasionally, you get one protein ending up in two families. This is
# rare, and harmless. If this happens, this is notified by family-input.pl,
# and the first one is taken, the rest ignored. 
# 
# The family-input.pl script tries to be careful with going from peptides
# (which the clusters contain) to genes (which are 'added' to the
# clusters). Occasionally, two peptides/transcripts from one gene end up in
# two different clusters. In that case, the family (and therefore
# description) having the best description is given  precedence. This is all
# written about to stderr, which is analyzed in the next step.
# 
# ------------------------------------------------------------------------

# Lastly, on the logfile from the loading (famload.err), run the statistics
# script:

$  $scripts/fam-stats.sh ensrv3 family110 ***REMOVED*** famload.err  > stat.out 2> stat.err

# The output gives a rough summary of the way things have  been going (in
# particular, the gene->family assignents. They should be roughly equal
# numbers (although I have seen +- 50% ... not sure what to make of that, it
# looked OK).
# 
# If the gene-descriptions (see gene-descriptions.txt) have not been done
# yet, do them, then run the script 

$ ensembl/scripts/desc-from-fam.sh coreDB -h host -u user famDB

# and replace the existing gene-description table with the new one (which is
# created in famDB.
