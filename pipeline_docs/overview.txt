This document gives an overview of the Ensembl pipeline, analysis
system and points the reader to documents with more detail about
setting up and using specific aspects of the system.


Introduction
------------

The Ensembl pipeline and analysis system exist to allow easy
automated annotation of genome sequences. The system is designed to
allow analyses that are dependent on one another to be sent
simultaneously to a compute resource. It has the capability to catch
and register errors and to retry failed analyses.

The analysis and pipeline code are stand-alone.

Details of the pipeline system (how it is set up, our standard usages
patterns and how to customise it) are described in another document:
ensembl-doc/pipeline_docs/the_ensembl_pipeline_infrastructure.txt.


Code requirements
-----------------

See: http://www.ensembl.org/info/using/api/api_installation.html

To run any piece of the Ensembl software you need the following.
Versions are current at the time of writing and will work with the
Ensembl code (you can try using more recent versions but we can't
guarantee they will work).

Perl 5.8, including the DBI and DBD::Mysql modules
MySQL (version 4.1)
Bioperl (version 0.7.2, 1.2.3 or 1.4)

Bioperl can be obtainned using CVS like this:
cvs -d :pserver:cvs@code.open-bio.org:/home/repository/bioperl login
(when prompted, the password is 'cvs')
then:
cvs -d :pserver:cvs@cvs.open-bio.org:/home/repository/bioperl checkout
-r bioperl-release-1-2-3 bioperl-live

Note that some parts of the code require older bioperl versions (0.7.2)
whilst other modules require newer bioperl versions (1.4).

You also need some Ensembl-specific Perl code:

ensembl
ensembl-pipeline
ensembl-analysis
ensembl-killlist

These are all available using CVS like this:
# password is CVSUSER is prompted
cvs -d :pserver:cvsuser@cvs.sanger.ac.uk:/cvsroot/ensembl checkout -r branch-ensembl-52 ensembl

This will checkout the core ensembl modules on a cvs branch called
branch-ensembl-52 (the code base use for Ensembl release 52). The
stable branch number will increment for every release.

The analysis, pipeline and kill-list code are not branched. We use the HEAD code:
cvs -d :pserver:cvsuser@cvs.sanger.ac.uk:/cvsroot/ensembl checkout -r HEAD ensembl-pipeline

cvs -d :pserver:cvsuser@cvs.sanger.ac.uk:/cvsroot/ensembl checkout -r HEAD ensembl-analysis

cvs -d :pserver:cvsuser@cvs.sanger.ac.uk:/cvsroot/ensembl checkout -r HEAD ensembl-killlist

It is recommended that all cvs code be downloaded at the same time, to 
minimise conflicts between older and newer version of different modules.


The Ensembl build process
-------------------------

The Ensembl analysis of most genomes is very similar and follows the
same basic structure.

First the sequence and assembly details are loaded into an Ensembl
MySQL database.
(See ensembl-doc/loading_sequence_into_ensembl.txt for details.)

Once loaded the actual analysis can begin. It usually consists of the
following stages.

Overview of stages
------------------ 
Sequence and assembly loading
1. Raw compute 
2. Genebuild
   a Targetted Build
   b Similarity Build
   c UTR Addition
   d GeneBuilder
3. ncRNA analysis
4. Pseudogene analysis
5. Protein annotation
6. ID cross mapping (Xrefs)
7. EST Genebuild


1. The Raw Compute
==================

We call the first stage of analysis the 'raw compute' stage. This
stage involves running several different analyses to find different
features in the genome. These include:

a. Repeat finding analyses
b. Ab initio genefinders, like Genscan
c. Blast hits using standard databases such as Uniprot and Unigene
d. Programs to find features like CpG islands and tRNAs in the genome
e. Placing markers on the genome

For details, please refer to ensembl-doc/pipeline_docs/the_raw_computes.txt.


2. The Genebuild
================

Next the Gene building steps are run. The overall aim is to produce the
best possible genome-wide set of coding transcript and gene structures. The
Genebuild involves several distinct stages.

a. Targetted Genebuild
----------------------

The Targetted Genebuild involves two main stages:
i.  Species-specific proteins are aligned to the genome using pmatch
    and subsequently filtered to get the best-in-genome hit(s) for each
    protein.
ii. Filtered pmatch hits from (i) are used to seed BLASTs in a
    specific region of the genome, and then the program Genewise is run to
    build a transcript structure for the protein on the genome.

b. Similarity Genebuild
-----------------------

The Targetted Genebuild is followed by the Similarity Genebuild. In
this step the protein-based blast results obtained from the Raw
Compute stage are used.  The process is very similar process to the
Targetted Genebuild, but the protein alignments being used to seed the
Genewise runs can come from different species.

For those species which have a lot of experimentally generated protein
sequence data, the Targetted Genebuild stage tends to provide the bulk
of genes in the build, as the Similarity Genebuild generated genes are
only used where a Targetted Genebuild gene is absent. However, in less
studied organisms less species-specific protein sequences will be
available and hence the similarity build plays a much more important
role in predicting genes.

c. UTR Addition
---------------

After these protein-based transcript predictions have been made, an
attempt is made to add UTR (untranslated region) sequences to the
ends. If cDNA sequences for the species in question are available,
these sequences are mapped to the genome using a program called
exonerate and the resultant genome-cDNA alignments are filtered to
only include the the 'best in genome' match. Where cDNAs mapped in
this manner overlap transcripts predicted in the preceding stages,
any non-translated region from the cDNA is spliced onto the prediction
as UTR.

At this stage a set of so called Blessed Genes can be added. Blessed
genes are genes whose structure is already known, for example from
manually curated gene sets, or special cases where we know that the
standard pipeline can't predict correctly (e.g. selenocysteine
genes). These genes are treated more carefully and, while they may
have UTR added, the process ensures that the CDS structure remains
unchanged.

Ditag information may be used in the UTR addition process, when
available.

d. The Genebuilder
------------------

Each of the prior stages of the genebuild process creates a set of
transcripts which may be partially redundant to one another. These
sets need to be merged to create a single non-redundant set of
transcripts. This reconciliation is performed by the Genebuilder
module. The Genebuilder compares transcripts from the different sets
and tries to combine or merge identical transcripts. When transcripts
are combined the supporting evidence for each prediction is transfered
to the new transcript. Overlapping transcripts are clustered into
genes.

Once a 'final' gene set has been obtained, a number of post-processing
procedures are applied to filter and annotate the predicted genes.

3. ncRNA Annotation
==================

ncRNA annotation is split into 2 stages which can run simultaneously:
miRNA detection.
ncRNA detection using Infernal
(tRNAs are already identified as part of the raw computes)
Further details about how to run all 3 stages are availiable in ncRNA.txt

4. Pseudogene Analysis
======================

Pseudogene analysis can have up to 3 stages:
Identification of genes with no 'real' exons,
Identification of retrotransposed genes,
Identification of pseudogenes using PSILC,
Generally only the first stage is run as the latter stages are prone to 
misannotate real genes as pseudogenes. 
Further details about how to run all 3 stages are availiable in Pseudogene.txt

5. Protein Annotation
=====================

Next the translations are dumped out of the database and a protein
annotation stage is performed. This serves to identify protein domains
from databases like Pfam or Prosite and features such as signal
peptides (with the program SignalP) and transmembrane domains (with
the program tmhmm).


6. ID mapping, Xrefs
====================

Ensembl stable identifiers (ENSGxxx, ENSTxxx, ENSPxxx, ENSExxx) are
assigned by mapping these IDs across from the previous Ensembl gene
set. New identifiers are assigned for any entities where we fail to
map an existing identifier.

We also run a cross-reference ('Xref') analysis, which maps each
protein from our own genes to entries in other databases such as
UniProt (SwissProt/TrEMBL), Refseq and species-specific gene name
databases (e.g. HGNC for human). This mapping provides links between
an Ensembl gene and these other databases, providing access to extra
information about the potential functionality of the gene.


7. EST Genebuild
================

For most species, EST-based gene predictions don't contribute to the
main Ensembl gene set. Instead we use this process to produce a
separate set of EST genes. The process is very similar to the cDNA
analysis. First the EST sequences are aligned to the genome using
exonerate. These alignments are then collapsed down into a non
redundant set of transcripts with open reading frames based on
clusters of overlapping ESTs, using TranscriptCoalescer module.



Other useful documents in the ensembl-doc cvs module
----------------------------------------------------

* loading_sequence_into_ensembl.txt
This describes how to load sequences from fasta files and assemblies
from agp files into your Ensembl database

* the_ensembl_pipeline_infrastructure.txt
This describes the pipeline infrastructure system and how to set it up
to run different analyses

* quick_start_pipeline_guide.txt
This describes how to get a test setup running for the pipeline on the
basis of ensembl-pipeline/test_system

* running_the_rawcomputes.txt
This describes how to run the raw compute stage of our analysis system

* running_the_markers.txt
This describes how to map STS markers from dbSTS and other sources
onto a genome

* running_the_genebuild.txt
This describes the processes of running the genebuild

* ncRNA.txt
This describes how to run annotation for non coding RNA

* Pseudogenes.txt
This describes how to run pseudogene annotation

* est_cdna_genebuild.txt
This describes the processes of running an EST or cDNA based genebuild

* running_the_protein_annotation.txt
This describes how to run the protein annotation stage

* using_the_xref_system.txt
This describes how to use our xref system

* custom_analyses.txt
This describes the sort of things you may want to consider if you are
setting up custom analyses in our system

* using_blast_in_the_pipeline.txt
This describes how our blast system functions and how best to use it

* batchsubmission_systems.txt
This describes how our various batch submission systems work and how
to set up a module for your system

* low_coverage_pre_site_setup.txt
This describes an automated system for producing a pre-site for a 
low-coverage genome.

* low_coverage_genebuild.txt
This describes the process of obtaining a set of gene-scaffolds and
genes for a low-coverage genome. 

