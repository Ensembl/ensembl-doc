This document covers how to run ncRNA annotations on one or more genomes using an automated
system. The second half of the document details the modules involved.
If you have any questions about it please contact dev@ensembl.org

Code
----

The ensembl pipeline like the ensembl core is coded in perl. In order to
run the ensembl pipeline you need perl and mysql installed. You also need
some ensembl specific code which are freely available from cvs

These are required

ensembl
ensembl-pipeline
ensembl-analysis
you also need bioperl which again, is freely available

bioperl-live (bioperl-release-1-2-3)


Currently the stable branch of the pipeline and analysis code is 
branch-ensembl-37. This code may work with more recent versions of the
core code but we can only guarantee it will work with the same branch

In addition the modules require:
RNAfold (part of the ViennaRNA package)
cmsearch (part of the Infernal package)
RFAM BLAST database, covariance models, description file and thresholds file
(As part of the Infernal module the RFAM  BLAST database is split into 2 files
one for high copy number ncRNAs and one for low copy number)

some of these are freely available on the web, others will need licenses

The automated pipeline is controlled from 2 perl scripts and a configuration file:
ncRNA_update.pl
predict_ncRNA.pl
ncRNA_update_config.pm
config_files.txt

These are located in ensembl-pipeline/scripts/ncRNA/

config_files.txt
================
This contains all the hard-coded config needed to run the pipeline and the analyses, this should not need to be changed.


ncRNA_update_config.pm
======================
This contains the configurable variables for the analysis, ie: what species to run on, the location of the databases to create,
search. It consists of an anonymous hash keyed on CONFIG ie:
CHICKEN => {
           # source db with dna dont want to write to this one
		DBNAME     => "gallus_gallus_core_36_1l",
		DBPORT     => "3365",
		DBHOST     => "ecs2",
		# DB to write to (Also the pipeline database)
		WRITEHOST  => "ia64f",
		WRITEPORT  => "3306",
		WRITENAME  => "chicken_ncRNA_update",
		OUTDIR     => "/path/to/output/directory",
		# mysql instance source db is on
		REFINS     => "ecs2my3365",
		# lsf load for source db
		REFLOAD    => 400,
		# mysql instance pipeline/output db is on
		WRITEINS   => "myia64f",
		# lsf load for pipeline/output db
		WRITELOAD  => 800,
	 },
The database identifiers called DB... refer to a reference core database containing the dna and the
assembly. The WRITE. databases act as both the pipeline database and the database to which the final
gene objects are written, these are created automatically by the script.
##################################
# Warning, if the WRITE database already exists it is deleted and recreated when the script is run ,
so be careful that you don't mix up the ref DB... database and the WRITE.... database.
the remaining config includes REFINS - this is the lsf name of the instance containing the reference
database
REFLOAD - the maximum LSF load allowed on the reference instance.
WRITEINS, WRITELOAD, the same but for the WRITE... database instance.
Other config:
DATADIR - where to write config files to
CVSDIR  - Where the cvs directory is for the ensembl branch you wish to use ( used for setting the PERL5LIB
path )
WRITEUSER - user name for writing to the database ? 
BIOPERLPATH - Where the cvs directory is for the bioperl branch you wish to use ( used for setting the PERL5LIB
path )
MIRBASEVERSION - Version number of miRBAse used
RFAMVERSION - Version number of RFAM used
# directory to make the blast databases in
BLASTDIR   - Where to store the databases for the blast search
# once this file is filled in correctly you can run ncRNA_update.pl

run ncRNA_update.pl
===================
This sets up the pipeline databases and starts the first stage of the analysis ie: a BLAST search

perl ncRNA_update.pl <options> 
  -pass *   the database write password 
  -verbose
  -dbsetup  this will create the pipeline databases (it will delete any existing databases with the same name on the same instance)
  -refresh  this obtains the latest copy of the RFAM and miRBase files and formats blast databases from them 
  -species  comma separated list of species from the config to work on, if blank all species are run
  -norfam   this flag blocks the RFAM analysis from running if you only want to update miRNAs

writes the rulemanager command and path to a shell script species.csh
* = required

When the script is run, first the configuration is written and checked, then the RFAM and miRBase files are prepared, if
specified. Next the databases are created and the appropriate data is copied from the reference databases, assembly, seq_regions
etc, next the pipeline set-up is done, the input ids and rules are created. Finally the rule managers are run, each with a separate
PERL5LIB pointing to the appropriate configuration files in the DATADIR.
The script then writes a series of shell scripts, one for each species which will contain the correct path and rulemanager command.
Just run the shell script to start the pipeline. A list of monitor command lines is provided for each database so you can watch the BLAST jobs running.

######WARNING#########
Dont cut and paste the rulemanger command line to start the pipeline without setting the perl path first as this can
cause problems; genes being written to the wrong databases and the like. Use the -run flag instead


predict_ncRNA.pl
================
This script runs the second stage of the analysis. This consists of first analysing the blast results and limiting the number of
hits to be analysed. The script prepares the input ids for the final stages  of both the miRBase and RFAM analysis.

The command line options are essentially the same as for the previous script.
perl predict_ncRNA.pl 
  -pass *    password 
  -species   species list 
  -verbose 
  -norfam    Only run miRNA annotation

(* required)

Again, once it has been run, use the appropriate shell script to restart the pipeline.

Note: When you run the final stage of the miRNA pipeline, little postscript files with pictures of miRNAs get written to the directory
where you ran the rulemanager from. This is nothing to worry about. RNAfold writes them by default and I cannot find a 
way of turning them off!

Once the analyses are run, the non coding RNA gene objects will have been stored in the pipeline database.

A final script: transfer_ncRNAs.pl issued to transfer the ncRNAs from the pipeline database into the database on the staging
server.
transfer_ncRNAs
  -pass * 
  -write       write protect off
  -verbose 
  -delete      deletes non coding genes that are already on the staging server before writing the new ones.
  -merge       If the new ncRNA overlaps an old ncRNA, delete the old one and replace it with the new one
  -increment   If the new ncRNA overlaps an old ncRNA, keep the old ncRNA
  -dbname *    the database to write to  on the staging server
  -dbhost * 
  -dbport * 
  -species *   name of the species (same as in the config) only 1 species at a time can be written
  -analysis *  analysis logic name of the genes to delete ie: ncRNA
  -xrefs       a file name in which to dump out all the xref data for use by the xref system
  -skipchecks  dont do checks
  -whitelist   list of dbids to keep
  -release *   intended emsembl release number

* = essential
Only 1 species at a time please
It is important to use the -xrefs flag to store the xref data as the xref system needs it.
The script checks the ncRNAs to remove duplicated genes from the set before they are written. It also will not allow an ncRNA to
be written to the staging server database if it overlaps a coding exon unless the dbID has been specified in the whitelist. This
has been used for instance in mouse where miRNAs were overlapping a hypothetical ORF that actually corresponded to a conceptual
translation of a non coding primary transcript.

This should be all you need to run the ncRNA analysis for a genome.

Please remember that we usually import annotation on the MT chromosome directly from the relevant Genbank file
so if this ncRNA pipeline predicts any ncRNAs on the MT chromosome then we usually delete these from the database.

The next section talks in detail about how the modules work.


==================================================================================================================================


This section covers the ncRNA annotation modules within the ensembl pipeline system. If
you have any questions about it please contact dev@ensembl.org

Non coding RNAs are involved in many biological processes and are increasingly
seen as important. As is the case with proteins, it is the overall structure of
the molecule which imparts function. However, while similar protein structures
are often reflected in a conserved amino acid sequence, sequences underlying 
RNA secondary structure are very variable; this makes ncRNAs difficult to 
detect using sequence alone.

Because of this, we use a variety of techniques to detect ncRNAs. First, a
combination of sensitive BLAST searches are used to identify likely targets,
then a covariance model search is used to measure the probability that the
targets can fold into the structures required. Other ncRNAs are added as part 
of the raw compute stage. 

Code
----

The ensembl pipeline like the ensembl core is coded in perl. In order to
run the ensembl pipeline you need perl and mysql installed. You also need
some ensembl specific code which are freely availible from cvs

These are required

ensembl
ensembl-pipeline
ensembl-analysis
you also need bioperl which again, is freely availible

bioperl-live (bioperl-release-1-2-3)


Currently the stable branch of the pipeline and analysis code is 
branch-ensembl-29. This code may work with more recent versions of the
core code but we can only guarrentee it will work with the same branch

In addition the modules require:
RNAfold (part of the ViennaRNA package)
cmsearch (part of the Infernal package)
RFAM BLAST database, covariance models, description file and thresholds file
(As part of the Infernal module the RFAM  BLAST database is split into 2 files
one for high copy number ncRNAs and one for low copy number)

some of these are freely available on the web, others will need licenses

The ncRNA pipeline is run as part of the genebuild and so uses the
Bio::EnsEMBL::Analysis::Config::Databases.pm module to define the sequence
database and the location of the database to write the non coding genes to.
The pipeline consists of :
	2 sets of BLAST runnables, 
	2 sets of gene identifying runnables,
	1 script. 
Both sets of BLAST modules can run on the same set of input ids, the most
effective results seem to be obtained using slices of around 200 kb.
The BLAST runnables require configuration in
Bio::EnsEMBL::Analysis::Config::Blast (see example at end of document and
using_blast_in_the_pipeline.txt)

Things to note:
The Infernal runnables  are currently only available on Linux machines.
You will need the flag table in your pipeline database 
(ensembl-pipeline/sql/flag.sql)

Modules overview:
=================

ncRNA annotation is divided into 3 parts:
	General ncRNA identification using Infernal
	Specific ncRNA annotation : miRNAs, tRNAs

tRNAs 
=====

These are already annotated as part of the raw compute process using
tRNAscan SE. (see running_the_raw_computes.txt)

Micro RNAs
==========

miRNAs share very high sequence identity across species, subsequently most
miRNAs are detectable by BLAST. The miRNA pipeline consists of a BLAST step
using : 
   
	Bio::EnsEMBL::Analysis::RunnableDB::BlastmiRNA
	
This module extend the BLAST runnables to allow clustering of 
overlapping BLAST hits and storing of the BLAST coverage.
(DnaAlignfeature score field is used to store coverage).

Following the BLAST step the miRNAs are identified and stored in the database
using:

	Bio::EnsEMBL::Analysis::RunnableDB::miRNA

	
This runnabledb need to access all the miRNA BLAST hits and so the module is
dependent on an accumulator job that waits for the miRNA BLASTs to finish.
They group the BLAST hits by miRNA family and ignore families with more
than 50 members as there is a high probability that they are hitting
repetitive sequences. miRNAs are identified from BLAST alignments that
contain the complete mature miRNA sequences and are able to fold into
hairpin structures as determined by RNAfold (part of the ViennaRNA
package).

The modules create and store single exon gene objects to represent the
miRNAs. Predicted secondary structure and the position of the mature miRNA
are stored on the transcript.

Other ncRNAs
============

Generally ncRNAs are more difficult to detect by Blast than miRNAs, this is
because they can have very different sequences yet share exactly the same
structures. Because of this a program called cmsearch is used that is a
part of the Infernal suite of programs:
SR Eddy, BMC Bioinformatics 3:18, 2002. 

The infermal suite of programs use a covariance model to identify ncRNAs on the
basis of both secondary structure aswell as sequence information; but because 
the Infernal programs are quite slow an initial blast step is used to narrow 
the search. Sequence identity within a family though can be low so the blast 
search is quite sensitive and can overpredict

This is the ncRNA BLAST runnabledb:
	Bio::EnsEMBL::Analysis::RunnableDB::BlastRfa
	
Similarly to the miRNA BLAST runnabledb; this module stores coverage in the 
score field of the resulting dna align features and cluster overlapping 
results. Representative sequences are taken for each ncRNA family in each
cluster. Coverage cutoffs are used  to reduce over prediction.
Two different BLAST searches are run; a WuBLAST on a database of high copy
number ncRNAs that align to repetitive sequences and a sensitive NCBI BLAST on
a database of ncRNA sequences that hit less frequently.

predict_ncRNA.pl
================

Once the BLAST step is complete it is necessary to run a script that
reduces the amount of overprediction in the BLAST results by grouping the
hits into families and taking a maximum of 2000 of the highest scoring hits
from each family for cmsearch to run on.

The script uses the Flag table to identify the sequences that are likely
candidates and creates and stores input ids based on flags for the Infernal
module to run on.

The script is in ensembl-pipeline/scripts

perl predict_ncRNA -dbname name -dbuser ensadmin -dbport 3306 -dbpass
******* -dbhost ecs1a -aln ncRNA -dln DummyFlag -chunk 50

-aln is the analysis logic name for the Infernal module
-dln is the dummy analysis that will have the input ids for Infernal
-chunk the number of flag ids to use in each job

Because there can be large numbers of BLAST hits generated by the BLAST 
runnables,the script proceeds on a family by family basis to avoid running
out of memory, the run time varies from a few minutes to several hours 
depending on how many BLAST hits are in the pipeline database. Generally
the script is fairly quick if the number of hits is less than about 2 million.

The Infernal runnabledb:
	Bio::EnsEMBL::Analysis::RunnableDB::Infernal
	
This run over the filtered BLAST hits and makes the ncRNA genes where the
Infernal scores are higher than the pre-defined thresholds for each family.
The modules create and store single exon gene objects and store the predicted
secondary structure of the ncRNA as a transcript attribute.

Schema 
------

The flag table contains the following columns:

flag_id     - The unique identifier of the flag
ensembl_id  - identifier of the flagged object
table_name  - the table in which the object is stored
analysis_id - Identifier of the analysis to run on the object

Running the ncRNA annotation
----------------------------

If the analysis and rules are set up correctly (see example below ) running
the pipeline should be straightforward.

1. make the input ids for the blasts (toplevel slices 200k)

2. run the rule manager - runs both BLASTs (miRNA and ncRNA) 

3. Accumulator job will run when the miRNA BLAST jobs finish, the miRNA
analysis should then run and write miRNA genes into the final genebuild
database.

4. run the predict_ncRNA script - identifies likely ncRNAs and makes input ids
for the Infernal module. (ensembl-pipeline/scripts/ncRNA/predict_ncRNA.pl)

ie : perl predict_ncRNA -dbname name -dbuser ensadmin -dbport 3306 -dbpass
******* -dbhost ecs1a -aln ncRNA -dln DummyFlag -chunk 50

5. re-run the rule manager - Infernal will run and write ncRNA genes into
the final genebuild database

Dependencies:
=============

DummySlice                  SubmitmiRNA
  SLICE	       GENOME
    ^            ^              ^
    |            |              |
 RfamBlast   BlastmiRNA	        /
  SLICE         SLICE          /
                 ^            /
(run script)     |           /
                 |          /
 DummmyFlag  BlastWait     /
   FLAG     ACCUMULATOR   /
    ^            ^       /
    |            |      /
    |	         |     /
 Infernal      miRNA  
   FLAG	       GENOME   


Checklist
=========

When running the ncRNA annotation it is worth checking these things out before
you start

1. Do you have all the executables, and data files for the analysis you want to
run? Are they pushed out across your compute farm where appropriate?

2. Do you have the flag table loaded into your pipeline database?

4. Does BatchQueue.pm contain entries for all the analyses you wish to run?

5. Have you filled in the analysis table?

6. Have you filled in the rule tables?

7. Have you filled in the BLAST configuration?

8. Are the appropriate dummy entries in the input_id_analysis table?

9. Have you tested jobs for your different analyses?


Example config:
===============

Analysis:
=========

[DummyFlag]
module=Dummy
input_id_type=FLAG

[DummySlice]
module=Dummy
input_id_type=SLICE

[SubmitmiRNA]
module=Dummy
input_id_type=GENOME

[RfamBlast]
db=Rfam
db_version=1
db_file=/data/blastdb/Rfam/Rfam.fasta
program=wublastn
program_version=1
program_file=wublastn
module=Bio::EnsEMBL::Analysis::RunnableDB::BlastRfam
input_id_type=SLICE

[BlastmiRNA]
db=hairpin.fa
db_version=1
db_file=/pfam/db/miRNA/blastdb/hairpin.fa
program=wublastn
program_file=wublastn
parameters=-hitdist=40, cpus = 1
module=Bio::EnsEMBL::Analysis::RunnableDB::BlastmiRNA
input_id_type=SLICE

[BlastWait]
module=Accumulator
input_id_type=ACCUMULATOR

[ncRNA]
db=Rfam
db_file=/data/blastdb/Rfam/
program=cmsearch
module=Bio::EnsEMBL::Analysis::RunnableDB::Infernal
gff_source=ensembl
gff_feature=gene
input_id_type=FLAG

[miRNA]
module=Bio::EnsEMBL::Analysis::RunnableDB::miRNA
input_id_type=GENOME

Rules:
======

[BlastmiRNA]
condition=DummySlice
[RfamBlast]
condition=DummySlice
[ncRNA]
condition=DummyFlag
[BlastWait]
condition=BlastmiRNA
[miRNA]
condition=BlastWait
condition=SubmitmiRNA

BLAST Config 
============

for Bio::EnsEMBL::Analysis::Config::Blast.pm
see using_blast_in_the_pipeline.txt

Rfam => 
{	
       BLAST_PARSER => 'Bio::EnsEMBL::Analysis::Tools::FilterBPlite',
       PARSER_PARAMS => {
                         -regex => '(\w+)\.\w+',
                         -query_type => undef,
                         -database_type => undef,
                        },
       BLAST_FILTER => undef,
       FILTER_PARAMS => {},
       BLAST_PARAMS => {
                        -unknown_error_string => 'FAILED',
                        -type => 'ncbi',
                       }
},
BlastmiRNA => 
{
       BLAST_PARSER => 'Bio::EnsEMBL::Analysis::Tools::BPliteWrapper',
       PARSER_PARAMS => {
                         -regex => '\w+\s+(\w+)',
                         -query_type => 'dna',
                         -database_type => 'dna',
                         },
       BLAST_FILTER => undef,
       FILTER_PARAMS => {},
       BLAST_PARAMS => {
                        -unknown_error_string => 'FAILED',
                        -type => 'wu',
                       }
}


