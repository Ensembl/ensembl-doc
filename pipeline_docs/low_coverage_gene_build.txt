==============================
RUNNING THE WGA2Genes PIPELINE
==============================

The function of this system is as follows: given a low-coverge/gappy
genome to annotate (the target), an annotated, reference genome (the
query) and a filtered whole-genome alignment (WGA) between the two,
project annotation from the query onto the target through the WGA, 
at the same time inferring a super-assembly of the small scaffolds
of the target into "gene scaffolds" that contain whole genes.  

========
OVERVIEW
========

The procedure has six phases:

(1) Calculation of candidate gene scaffolds and gene structures

    This step is performed by the ensembl-analyis RunnableDB WGA2Genes, 
    the input_id is a slice id for the reference genome. This step works 
    best if the slice ids are "intelligently" constructed, and there is a 
    script to do this. 

(2) Consolidation of gene scaffolds and extension of components. 
 
    This step is performed by the ensembl-analysis script 
    wga2genes/merge_and_extend_gene_scaffolds.pl. It joins gene scaffold
    components together into larger assemblies where appropriate, and
    also extends their components such that for every scaffold that 
    contributes to a gene scaffold, every base pair is used somewhere
    (either in one large piece or a number of smaller pieces). 

(3) Loading of new assembly and gene structures

    There are two products of the above initial steps: an AGP describing
    the assembly of the gene scaffolds from their consituent scaffolds, and
    GFF-like file describing the gene structures on these gene scaffolds. These
    can be loaded into your core target database with the ensembl-analysis
    scripts wga2genes/load_gene_scaffolds.pl and wga2genes/load_transcripts.pl

(4) Re-run scaffold-level raw computes on new top-level pieces

    Because many of the original scaffolds will be fragmented in the
    gene scaffolds, it is necessary to re-run scaffold-level analyses
    on the new top-level co-ordinate system (on-the-fly projection will
    not always be possible, particularly for features that straddle a
    break-point). This step is not needed if the results of all raw 
    computes were stored at the sequence level (usually contigs).

(5) Run some "standard" gene-build components

    It is often sensible to run some Genewises/Exonerates 
    at this point, in the style of the classical gene-build, targetting 
    regions not covered by projected genes. Whether you do this or not
    depends on how much species-specific data is available. 

    Note: protein annotation and xrefs are still required as the last
    steps of the build process.

(6) Extra things

    There are one or two things to do before hand-over that are specific
    to low-coverage builds. 

Note that only steps 1-3 and 6 are described in this document. Help with steps 4 
and 5 can be found in the documents "the_raw_computes.txt" and
"the_genebuild_process.txt."


============
REQUIREMENTS
============

- A query core database

  This database should contain the assembly and annotatation of the 
  reference genome. This will be referred to as 'the_query_core_db'.

- A target core database

  This database should contain the sequence and assembly of the low-
  coverage genome to be annotated. This will be referred to as
  'the_target_core_db'

- A compara database

  This database should contain the processed whole-genome alignment 
  (WGA) between the query and target genomes. This alignment *must* have
  the following property: each bp in the target genome should be represented 
  at most once. See other documentation for how to produce a useful
  alignment with this property. This database will be referred to as
  'the_compara_db', and the MethodLinkType of the processed alignment to be
  used as 'WGA_method_link_type'.

- A pipeline database

  This facilitates the running of the first, WGA2Genes stage (the assumption 
  is that you will have already set up a pipeline database for the preparation 
  and processing of the WGA). This database will be referred to as 
  'the_pipeline_db'. It will often be the case that your pipeline database is
  the same as your target core database.

- A kill-list

  This is a file containing a list of genes/transcripts in the query database
  that should be ignored during the process. This "kill-list" should contain, 
  at the very least, all transcripts in the query database that have a coding 
  length that is not modulo-3 in length (the code throws an exception when
  trying to project these). It can also contain other entries for gene structures 
  that are known to be wrong in the query database. The script  
  ensembl-analysis/scripts/wga2genes/identify_bad_source_transcripts.pl can be run 
  against the query database to make an initial kill-list. The kill-list file will
  be referred to as 'the_kill_list_file'.

- Code

  The following CVS check-outs are required: 

  ensembl (plus bioperl)
  ensembl-analysis
  ensembl-compara
  ensembl-pipeline


===================================================================
STEP 1: Calculation of Candidate gene scaffolds and gene structures
===================================================================

This step is performed by the ensembl-analysis RunnableDB WGA2Genes,
behaviour being controlled by a config file with the same name. 

The input ids are identifiers of slices from the reference (query) 
genome that should contain one or more genes. Because each of these
slices can be considered independently, the process can be parallelised
on the farm using the pipeline. 

Unlike normal RunnableDBs, the output is not written to a database,
but instead to stdout, in AGP and GFF format. 

------------
Config setup
------------

It is necessary to plug in the details of the the_query_core_db,
the_target_core_db, the_compara_db and the_kill_list_file
into the appropriate places in the config file, and to set INPUT_METHOD_LINK_TYPE 
to WGA_method_link_type

The values of other attributes should only be changed if you know what 
you're doing (the .example file gives an overview of the function of each 
attribute).

---------------
Pipeline set-up
---------------

(*) Analysis, rule and BatchQueue set-up

Use ensembl-pipeline/scripts/analysis_setup.pl with the following:

<cut>
[WGA2Genes]
module=WGA2Genes
input_id_type=HUMANGENESLICE

[SubmitHumanGeneSlice]
input_id_type=HUMANGENESLICE
</cut>

And ensembl-pipeline/scripts/rule_setup.pl with the following:

<cut>
[WGA2Genes]
condition=SubmitHumanGeneSlice
</cut>

And ensembl-pipeline/modules/Bio/EnsEMBL/Pipeline/Config/BatchQueue.pm
should have the following minimally (you might want to add some
resource requirements to check loads on the servers containing
the_query_core_db, the_target_core_db, the_compara_db, and 
the_pipeline_db it play nicely with the farm. The results are written to
the_output_dir specified below, so make sure that this exists and has lots
of space. Also, make sure cleanup is set to 'no' below to avoid
rare problems with duplicate output):


<cut>
    {
      logic_name => 'WGA2Genes',
      runnabledb_path => 'Bio/EnsEMBL/Analysis/RunnableDB',
      batch_size => 500,
      resource   => '',
      retries    => 3,
      sub_args   => '',
      runner     => '',
      queue      => 'normal',
      output_dir => 'the_output_dir',
      cleanup => 'no',
    },
</cut>


(*) Input ID generation

The generation of input-ids for the WGA2Genes RunnableDB is an
important step because, due to the way the procedure works, different
segmentations of the query genome can give rise to different
results. The ensembl-pipeline script wga2genes/make_wga2genes_iids.pl
uses alignments from the compara database and genes from the query
database to determine "sensible" regions in the query to process with
a single job.

This script should be run for each top-level slice in the query
genome. However, only top-level sequences that both (a) are aligned
to the target genomes, and (b) contain non-killed genes/transcripts, need 
input ids (for the human genome, this means that haplotypes, which are not 
treated by compara, can be ignored). If the script is not supplied with a 
seq_region_name, it will contruct input ids for all top-level, reference
(i.e. no HAPs) non-duplicate (i.e. PARs present only only once)
sequences. This can take a bit of time, so it pays to parallelise the
task by using the fact that each top-level sequence region can
be treated independently. So you might proceed in the following manner:


% foreach i (1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X Y)
foreach? perl ensembl-pipeline/scripts/wga2genes/make_wga2genes_iids.pl -dbname the_pipeline_db.name -dbhost *** -dbuser *** -dbpass *** -querydbname the_query_db.name -querydbhost *** -querydbport *** -targetdbname the_target_db.name -targetdbhost *** -comparadbname the_compara_db.name -comparadbhost *** -aligntype WGA_method_link_type -logic SubmitHumanGeneSlice -kill the_kill_list_file  -write -seq_region_name $i
foreach? end

(note that here the Mitochondrion is exluded; it is common to do this 
because the annotated mitochrondrion is usally loaded separately for 
the target genome). 

--------------------
Things to be wary of
--------------------

- If testing with test_RunnableDB, do not use the "-verbose"
  flag. This assumes that the output is reference to an arracy of
  genes/features, which in this case it is not. Instead, use the
  "-write" flag, which writes the output to the display (the results
  are not written back to a database in this system). 

- It is normal to get warnings about attributes ("Cannot get
  attributes without an adaptor") and alignent features ("Insert
  followed by Delete") during this process.


=====================================================
STEP 2: Consolidation and extension of gene scaffolds
=====================================================

Because this process needs to consider the data for all gene scaffolds at 
once, it is performed by a single run of a script. 

- extraction of lines from outfiles from Step 1

% perl -ne '/^\#\#-AGP\s+(.+)/ and print "$1\n";' outdir/*.out > gene_scaffolds.raw.agp
% perl -ne '/^\#\#-GENES\s+(.+)/ and print "$1\n";' outdir/*.out > gene_scaffolds.raw.genes

- Run merge/consolidation script

% perl merge_and_extend_gene_scaffolds.pl -dbname the_target_db.name -dbuser *** -dbhost *** -agp gene_scaffolds.raw.agp -genes gene_scaffolds.raw.genes -outagp gene_scaffolds.merged.agp -outgenes gene_scaffolds.merged.genes -outlog merge.log

===============================================
STEP 3: Loading of assembly and gene structures
===============================================

perl load_gene_scaffolds.pl -dbname the_target_db.name -dbuser *** -dbpass *** -dbhost *** -asm_coord_sys_name genescaffold -cmp_coord_sys_name scaffold -seqlevel -directlevel gene_scaffolds.merged.agp 

perl load_transcripts.pl -dbname the_target_db.name -dbuser *** -dbpass *** -dbhost *** -genelogic WGA2Genes -sflogic ensembl_projection gene_scaffolds.merged.genes


===================
STEP 6: Extra stuff
===================

-------------------
Pseudogene analysis
-------------------

Because the system routinely produces transcript structures that include
exons placed in gaps, the standard Pseudogene-calling code is inappropriate
for these 2x builds. A specilised derivative RunnableDB, Pseudogene2x, should
be run instead. The config and set-up are the same as the standard system. 
However, it might be advisable to increase PS_FRAMESHIFT_INTRON_LENGTH from
the standard 9 to around 20. 

Tip: when generating pipeline input-ids for this, it's much faster to restrict
to those toplevel sequences that have genes on; if it contains no genes, 
there's no need for the Pseudogene code to even look at it. 

-----
xrefs
-----

In order that the web-site contains links to the human source gene for 
each projected entity, it is necessary to add this information as xrefs. 
This can be done by the following script, which should be run *after*
the main core xrefs have been loaded:

perl add_source_xrefs.pl -dbname the_target_db.name -dbuser *** -dbpass *** -dbhost *** -srcdbname the_query_db.name -srcdbuser *** -srcdbpass *** -srcdbhost *** -srcdbport ***
